import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from google.oauth2.service_account import Credentials
from pandas_gbq import read_gbq

# --- ì´ˆê¸° ì„¤ì • ë° í˜ì´ì§€ êµ¬ì„± ---
st.set_page_config(layout="wide", page_title="ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")

# --- ë°ì´í„° ë¡œë”© (BigQuery) ---
@st.cache_data(ttl=3600)
def load_company_data():
    """Google BigQueryì—ì„œ TDS ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ ìˆ˜í–‰"""
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"])
        project_id = st.secrets["gcp_service_account"]["project_id"]
        table_full_id = f"{project_id}.demo_data.tds_data"
        df = read_gbq(f"SELECT * FROM `{table_full_id}`", project_id=project_id, credentials=creds)

        if df.empty:
            st.error("BigQueryì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ì§€ë§Œ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        # ì§€ëŠ¥í˜• ì»¬ëŸ¼ëª… ì •ì œ
        df.columns = [re.sub(r'[^a-z0-9]+', '_', col.lower().strip()) for col in df.columns]

        required_cols = ['date', 'volume', 'value', 'reported_product_name', 'export_country', 'exporter', 'importer', 'hs_code']
        if not all(col in df.columns for col in required_cols):
            st.error(f"BigQuery í…Œì´ë¸”ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (í•„ìˆ˜: {required_cols})")
            st.info(f"ì‹¤ì œ ì»¬ëŸ¼ëª…: {df.columns.tolist()}")
            return None

        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        for col in ['volume', 'value']:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce')

        df.dropna(subset=['date', 'volume', 'value', 'importer', 'exporter'], inplace=True)
        df = df[(df['volume'] > 0) & (df['value'] > 0)].copy() # 0ë³´ë‹¤ í° ê°’ë§Œ ì‚¬ìš©
        
        # í´ë¦¬ë‹ í›„ unitPrice ê³„ì‚°
        df['unitPrice'] = df['value'] / df['volume']
        
        # ë„ˆë¬´ ë¹„ì‹¸ê±°ë‚˜ ì‹¼ ì´ìƒì¹˜ ì œê±° (IQR ë°©ì‹)
        Q1 = df['unitPrice'].quantile(0.25)
        Q3 = df['unitPrice'].quantile(0.75)
        IQR = Q3 - Q1
        df = df[~((df['unitPrice'] < (Q1 - 1.5 * IQR)) | (df['unitPrice'] > (Q3 + 1.5 * IQR)))]
        
        return df if not df.empty else None
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# --- ë¶„ì„ í—¬í¼ í•¨ìˆ˜ ---
def clean_text(text):
    if not isinstance(text, str): return ''
    text = text.lower()
    text = re.sub(r'\(.*?\)|\[.*?\]', ' ', text)
    text = re.sub(r'(\d+)\s*(?:y|yo|year|years|old|ë…„ì‚°|ë…„)', r'\1', text)
    text = re.sub(r'[^a-z0-9\s\uac00-\ud7a3]', ' ', text)
    text = re.sub(r'\bì‚°\b', ' ', text)
    return ' '.join(text.split())

def name_clusters(df, cluster_col='cluster'):
    """K-Means í´ëŸ¬ìŠ¤í„°ì— ë™ì ìœ¼ë¡œ ì´ë¦„ì„ ë¶€ì—¬í•©ë‹ˆë‹¤."""
    centroids = df.groupby(cluster_col).agg({
        'Total_Volume': 'mean',
        'Avg_UnitPrice': 'mean',
        'Trade_Count': 'mean'
    }).reset_index()

    # ê° ì§€í‘œì˜ ìˆœìœ„ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ: Volume, Count / ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ: Price)
    centroids['volume_rank'] = centroids['Total_Volume'].rank(ascending=False)
    centroids['price_rank'] = centroids['Avg_UnitPrice'].rank(ascending=True)
    centroids['count_rank'] = centroids['Trade_Count'].rank(ascending=False)
    
    # ê°€ì¤‘ì¹˜ í•©ì‚°ìœ¼ë¡œ ì¢…í•© ì ìˆ˜ ê³„ì‚°
    centroids['total_score'] = centroids['volume_rank'] * 0.4 + centroids['price_rank'] * 0.4 + centroids['count_rank'] * 0.2
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì´ë¦„ ë¶€ì—¬
    sorted_centroids = centroids.sort_values('total_score')
    
    names = ["ì†Œê·œëª¨/ê³ ê°€ì¹˜ ê·¸ë£¹", "ì¤‘ê²¬/ê· í˜• ê·¸ë£¹", "ëŒ€ê·œëª¨/ê°€ì„±ë¹„ ê·¸ë£¹"]
    if len(sorted_centroids) < 3:
        names = ["A ê·¸ë£¹", "B ê·¸ë£¹"] # í´ëŸ¬ìŠ¤í„°ê°€ 2ê°œì¼ ê²½ìš°

    name_map = {row[cluster_col]: names[i] if i < len(names) else f"{chr(ord('A')+i)} ê·¸ë£¹" for i, row in sorted_centroids.iterrows()}
    return name_map

def perform_clustering(importer_stats):
    """K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # í´ëŸ¬ìŠ¤í„°ë§ì— ì‚¬ìš©í•  íŠ¹ì„± ì„ íƒ
    features = importer_stats[['Total_Volume', 'Avg_UnitPrice', 'Trade_Count']].copy()
    
    # ë°ì´í„°ê°€ 3ê°œ ë¯¸ë§Œì´ë©´ í´ëŸ¬ìŠ¤í„°ë§ ë¶ˆê°€
    if len(features) < 3:
        return None, None

    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)

    # K-Means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ (k=3)
    kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
    importer_stats['cluster'] = kmeans.fit_predict(scaled_features)
    
    # í´ëŸ¬ìŠ¤í„° ì´ë¦„ ë¶€ì—¬
    cluster_name_map = name_clusters(importer_stats)
    importer_stats['Cluster_Name'] = importer_stats['cluster'].map(cluster_name_map)
    
    return importer_stats, cluster_name_map

# --- ë©”ì¸ ë¶„ì„ ë¡œì§ ---
def run_all_analysis(user_inputs, full_company_data, selected_products, target_importer_name):
    analysis_result = {"overview": {}, "positioning": {}, "supply_chain": {}}
    
    # 1. ë°ì´í„° í•„í„°ë§: ë¶„ì„ì— ì‚¬ìš©í•  ë°ì´í„°ë§Œ ì„ íƒ
    analysis_data = full_company_data[full_company_data['reported_product_name'].isin(selected_products)].copy()
    if analysis_data.empty:
        return analysis_result

    # 2. ìˆ˜ì…ì‚¬ë³„ í†µê³„ ì§‘ê³„
    importer_stats = analysis_data.groupby('importer').agg(
        Total_Value=('value', 'sum'),
        Total_Volume=('volume', 'sum'),
        Trade_Count=('value', 'count'),
        Avg_UnitPrice=('unitPrice', 'mean')
    ).reset_index()

    if importer_stats.empty or importer_stats['Total_Volume'].sum() == 0:
        return analysis_result

    importer_stats = importer_stats.sort_values('Total_Value', ascending=False).reset_index(drop=True)
    
    # 3. í¬ì§€ì…”ë‹ ë¶„ì„ (ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹ + AI ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§)
    # 3-1. ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹
    importer_stats['cum_share'] = importer_stats['Total_Value'].cumsum() / importer_stats['Total_Value'].sum()
    market_leaders = importer_stats[importer_stats['cum_share'] <= 0.7]
    
    direct_peers = pd.DataFrame()
    try:
        target_rank = importer_stats[importer_stats['importer'] == target_importer_name].index[0]
        rank_margin = max(1, int(len(importer_stats) * 0.1))
        direct_peers = importer_stats.iloc[max(0, target_rank - rank_margin):min(len(importer_stats), target_rank + rank_margin + 1)]
    except IndexError: pass # íƒ€ê²Ÿ ì—…ì²´ê°€ ë°ì´í„°ì— ì—†ì„ ê²½ìš°

    price_achievers_candidates = importer_stats[importer_stats['Trade_Count'] >= 2]
    price_achievers = price_achievers_candidates[price_achievers_candidates['Avg_UnitPrice'] <= price_achievers_candidates['Avg_UnitPrice'].quantile(0.15)] if not price_achievers_candidates.empty else pd.DataFrame()
    
    # 3-2. AI ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
    clustered_stats, cluster_names = perform_clustering(importer_stats.copy())

    analysis_result['positioning'] = {
        "importer_stats": importer_stats,
        "clustered_stats": clustered_stats,
        "cluster_names": cluster_names,
        "rule_based_groups": {"Market Leaders": market_leaders, "Direct Peers": direct_peers, "Price Achievers": price_achievers},
        "target_stats": importer_stats[importer_stats['importer'] == target_importer_name]
    }

    # 4. ê³µê¸‰ë§ ë¶„ì„ (ë¹„ìš© ì ˆê° ë° ë¦¬ìŠ¤í¬ ë¶„ì„)
    user_input = user_inputs[0] # ëŒ€í‘œ ì‚¬ìš©ì ì…ë ¥ ì‚¬ìš©
    user_avg_price = user_input['Value'] / user_input['Volume'] if user_input['Volume'] > 0 else 0
    
    # ëŒ€ì•ˆ ê³µê¸‰ì²˜ íƒìƒ‰ (ì‚¬ìš©ìë³´ë‹¤ ì €ë ´í•œ ë‹¨ê°€ë¡œ ë™ì¼ ì œí’ˆêµ°ì„ ê³µê¸‰í•˜ëŠ” ìˆ˜ì¶œì—…ì²´)
    alternative_suppliers = analysis_data[
        (analysis_data['exporter'].str.upper() != user_input['Exporter'].upper()) &
        (analysis_data['unitPrice'] < user_avg_price)
    ]
    
    if not alternative_suppliers.empty:
        supplier_analysis = alternative_suppliers.groupby('exporter').agg(
            Avg_UnitPrice=('unitPrice', 'mean'),
            Trade_Count=('value', 'count'),
            Num_Importers=('importer', 'nunique')
        ).reset_index().sort_values('Avg_UnitPrice')
        
        # ê¸°íšŒì™€ ì•ˆì •ì„± ì§€í‘œ ì¶”ê°€
        supplier_analysis['Price_Saving_Pct'] = (1 - supplier_analysis['Avg_UnitPrice'] / user_avg_price) * 100
        # ì•ˆì •ì„± ì ìˆ˜: ê±°ë˜ ê±´ìˆ˜ì™€ ê±°ë˜ì²˜ ìˆ˜ì— ë¡œê·¸ë¥¼ ì”Œì›Œ ì •ê·œí™” (í•œìª½ì— ì¹˜ìš°ì¹˜ì§€ ì•Šê²Œ)
        supplier_analysis['Stability_Score'] = np.log1p(supplier_analysis['Trade_Count']) + np.log1p(supplier_analysis['Num_Importers'])
        
        analysis_result['supply_chain'] = {
            "user_avg_price": user_avg_price,
            "user_total_volume": sum(item['Volume'] for item in user_inputs),
            "alternatives": supplier_analysis
        }
        
    return analysis_result


# --- UI Components ---
def login_screen():
    st.title("ğŸ” ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.write("ì†”ë£¨ì…˜ ì ‘ì†ì„ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    with st.form("login_form"):
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.form_submit_button("ì ‘ì†í•˜ê¸°"):
            if password == st.secrets.get("APP_PASSWORD", "tridgeDemo_2025"):
                st.session_state['logged_in'] = True
                st.rerun()
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def main_dashboard(company_data):
    st.title("ğŸ“ˆ ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.markdown("íŠ¸ë¦¿ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì¥ ë‚´ ê²½ìŸë ¥ì„ ì§„ë‹¨í•˜ê³  ë¹„ìš© ì ˆê° ê¸°íšŒë¥¼ í¬ì°©í•˜ì„¸ìš”.")
    
    # ì‚¬ìš©ì ì…ë ¥ UI
    with st.expander("STEP 1: ë¶„ì„ ì •ë³´ ì…ë ¥", expanded='analysis_result' not in st.session_state):
        importer_name = st.text_input("1. ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="importer_name").upper()
        if 'rows' not in st.session_state: st.session_state['rows'] = [{'id': 1}]

        for i, row in enumerate(st.session_state.rows):
            # ... (ê¸°ì¡´ ì…ë ¥ UI ì½”ë“œì™€ ë™ì¼, ìƒëµ) ...
            pass # Keep your original detailed input UI code here
        
        # For demonstration, a simplified input is used below.
        # Replace with your full input UI.
        if 'product_name_0' not in st.session_state:
            st.session_state.product_name_0 = "Whisky A 12YO"
            st.session_state.hscode_0 = "220830"
            st.session_state.volume_0 = 1000
            st.session_state.value_0 = 50000
            st.session_state.final_exporter_0 = "DIAGEO"
        
        st.text_input("ì œí’ˆ ìƒì„¸ëª…", key="product_name_0")
        st.text_input("HS-CODE", key="hscode_0")
        st.number_input("ìˆ˜ì… ì¤‘ëŸ‰(KG)", key="volume_0")
        st.number_input("ì´ ìˆ˜ì…ê¸ˆì•¡(USD)", key="value_0")
        st.text_input("ìˆ˜ì¶œì—…ì²´", key="final_exporter_0")

        if st.button("ë¶„ì„í•˜ê¸°", type="primary"):
            with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                all_purchase_data = []
                for i in range(len(st.session_state.get('rows', [{'id':1}]))):
                     entry = {
                        'Reported Product Name': st.session_state.get(f'product_name_{i}', ''),
                        'HS-CODE': st.session_state.get(f'hscode_{i}', ''),
                        'Exporter': st.session_state.get(f'final_exporter_{i}', '').upper(),
                        'Volume': st.session_state.get(f'volume_{i}', 0),
                        'Value': st.session_state.get(f'value_{i}', 0)
                     }
                     if not all([entry['Reported Product Name'], entry['Volume'] > 0, entry['Value'] > 0]):
                        st.error(f"ìˆ˜ì… ë‚´ì—­ {i+1}ì˜ í•„ìˆ˜ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."); return
                     all_purchase_data.append(entry)

                purchase_df = pd.DataFrame(all_purchase_data)
                purchase_df['cleaned_name'] = purchase_df['Reported Product Name'].apply(clean_text)
                
                # ê·¸ë£¹í™” ë¡œì§ (ë™ì¼ í’ˆëª© í•©ì‚°)
                agg_funcs = {
                    'Volume': 'sum', 'Value': 'sum', 
                    'Reported Product Name': 'first', 'HS-CODE': 'first', 'Exporter': 'first'
                }
                aggregated_purchase_df = purchase_df.groupby('cleaned_name', as_index=False).agg(agg_funcs)

                analysis_groups = []
                company_data['cleaned_name'] = company_data['reported_product_name'].apply(clean_text)
                for _, row in aggregated_purchase_df.iterrows():
                    entry = row.to_dict()
                    user_tokens = set(entry['cleaned_name'].split())
                    is_match = lambda name: user_tokens.issubset(set(str(name).split()))
                    matched_df = company_data[company_data['cleaned_name'].apply(is_match)]
                    matched_products = sorted(matched_df['reported_product_name'].unique().tolist())
                    
                    # ê·¸ë£¹ë³„ ë¶„ì„ ì‹¤í–‰
                    result = run_all_analysis([entry], company_data, matched_products, importer_name)
                    analysis_groups.append({
                        "user_input": entry,
                        "matched_products": matched_products,
                        "selected_products": matched_products,
                        "result": result
                    })

                st.session_state['importer_name_result'] = importer_name
                st.session_state['analysis_groups'] = analysis_groups

    if 'analysis_groups' in st.session_state:
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        for i, group in enumerate(st.session_state.analysis_groups):
            product_name = group['user_input']['Reported Product Name']
            st.subheader(f"ë¶„ì„ ê·¸ë£¹: \"{product_name}\"")
            result = group['result']
            
            # --- PART 1: ë§ˆì¼“ í¬ì§€ì…˜ ë¶„ì„ ---
            st.markdown("#### PART 1. ë§ˆì¼“ í¬ì§€ì…˜ ë¶„ì„")
            p_res = result.get('positioning')
            if not p_res or p_res['importer_stats'].empty:
                st.info("í¬ì§€ì…˜ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                continue

            # ê°œì„  1: ë²„ë¸” ì°¨íŠ¸ ë¡œì§
            importer_stats = p_res['importer_stats']
            target_name = st.session_state.get('importer_name_result', '')
            
            top_5 = importer_stats.head(5)
            direct_peers = p_res['rule_based_groups']['Direct Peers']
            target_row = importer_stats[importer_stats['importer'] == target_name]
            
            plot_df = pd.concat([top_5, direct_peers, target_row]).drop_duplicates().reset_index(drop=True)
            
            # ìµëª…í™” ë° ê·€ì‚¬ ê°•ì¡°
            plot_df['Anonymized_Importer'] = [f"{chr(ord('A')+j)}ì‚¬" if imp != target_name else target_name for j, imp in enumerate(plot_df['importer'])]
            plot_df['size'] = np.log1p(plot_df['Total_Value']) # ë¡œê·¸ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë²„ë¸” í¬ê¸° ì¡°ì ˆ
            plot_df['color'] = np.where(plot_df['importer'] == target_name, 'ê·€ì‚¬', 'ê²½ìŸì‚¬')
            plot_df['symbol'] = np.where(plot_df['importer'] == target_name, 'star', 'circle')

            fig = px.scatter(
                plot_df, x='Total_Volume', y='Avg_UnitPrice', size='size', 
                color='color', symbol='symbol',
                hover_name='Anonymized_Importer',
                hover_data={'Total_Volume': ':,', 'Avg_UnitPrice': ':.2f', 'Total_Value':':,', 'size':False, 'color':False, 'symbol':False},
                log_x=True,
                title="ìˆ˜ì…ì‚¬ í¬ì§€ì…”ë‹ ë§µ (Top 5, ìœ ì‚¬ ê²½ìŸì‚¬, ë° ê·€ì‚¬)",
                labels={'Total_Volume': 'ì´ ìˆ˜ì… ì¤‘ëŸ‰ (KG, Log Scale)', 'Avg_UnitPrice': 'í‰ê·  ìˆ˜ì… ë‹¨ê°€ (USD/KG)'},
                color_discrete_map={'ê·€ì‚¬': 'orange', 'ê²½ìŸì‚¬': 'grey'},
                symbol_sequence=['star', 'circle']
            )
            fig.update_traces(marker_line_width=1, marker_line_color='black')
            st.plotly_chart(fig, use_container_width=True)

            # ê°œì„  2: ê·¸ë£¹ ë¶„ë¥˜ ë°©ì‹ ì„ íƒ
            st.markdown("##### ê²½ìŸì‚¬ ê·¸ë£¹ ë¶„ì„")
            grouping_method = st.radio("ê·¸ë£¹ ë¶„ë¥˜ ë°©ì‹ ì„ íƒ:", ["ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹", "AI ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘ (K-Means)"], horizontal=True, key=f"group_method_{i}")

            if grouping_method == "ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹":
                groups = p_res['rule_based_groups']
                st.info("ì‹œì¥ ì„ ë„(ëˆ„ì  ì ìœ ìœ¨ 70%), ìœ ì‚¬ ê·œëª¨(ìˆœìœ„ Â±10%), ìµœì €ê°€ ë‹¬ì„±(ë‹¨ê°€ í•˜ìœ„ 15%) ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
                # ì—¬ê¸°ì— ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹ì— ëŒ€í•œ ì‹œê°í™” (ì˜ˆ: Box Plot) ì¶”ê°€ ê°€ëŠ¥
                
            else: # AI ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘
                if p_res.get('clustered_stats') is not None:
                    st.info("AIê°€ ìˆ˜ì… ê·œëª¨, ë‹¨ê°€, ë¹ˆë„ë¥¼ ì¢…í•©í•˜ì—¬ ìœ ì‚¬í•œ ì—…ì²´ë¼ë¦¬ 3ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
                    fig_cluster_box = px.box(p_res['clustered_stats'], x='Cluster_Name', y='Avg_UnitPrice',
                                             title="AI ê¸°ë°˜ ê·¸ë£¹ë³„ ë‹¨ê°€ ë¶„í¬", points='all',
                                             labels={'Cluster_Name': 'ê·¸ë£¹ ìœ í˜•', 'Avg_UnitPrice': 'í‰ê·  ìˆ˜ì… ë‹¨ê°€'})
                    # ê·€ì‚¬ ìœ„ì¹˜ ì ì„ ìœ¼ë¡œ í‘œì‹œ
                    if not p_res['target_stats'].empty:
                        target_price = p_res['target_stats']['Avg_UnitPrice'].iloc[0]
                        fig_cluster_box.add_hline(y=target_price, line_dash="dot", line_color="orange", annotation_text="ê·€ì‚¬ ë‹¨ê°€")
                    st.plotly_chart(fig_cluster_box, use_container_width=True)
                else:
                    st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ AI ê¸°ë°˜ ê·¸ë£¹í•‘ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


            # --- PART 2: ê³µê¸‰ë§ ë¶„ì„ ---
            st.markdown("---")
            st.markdown("#### PART 2. ê³µê¸‰ë§ ë¶„ì„ ë° ë¹„ìš© ì ˆê° ì‹œë®¬ë ˆì´ì…˜")
            s_res = result.get('supply_chain')
            if not s_res or s_res['alternatives'].empty:
                st.info("í˜„ì¬ ê±°ë˜ ì¡°ê±´ë³´ë‹¤ ë” ì €ë ´í•œ ëŒ€ì•ˆ ê³µê¸‰ì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # ê°œì„  3: ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ ë™ì‹œ ì œì‹œ
                alts = s_res['alternatives']
                best_deal = alts.iloc[0]

                st.success(f"**ë¹„ìš© ì ˆê° ê¸°íšŒ í¬ì°©!** í˜„ì¬ ê±°ë˜ì²˜ë³´ë‹¤ **ìµœëŒ€ {best_deal['Price_Saving_Pct']:.1f}%** ì €ë ´í•œ ë‹¨ê°€ë¡œ ê³µê¸‰í•˜ëŠ” ëŒ€ì²´ ê±°ë˜ì²˜ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
                
                col1, col2 = st.columns(2)
                with col1:
                    target_saving_pct = st.slider(
                        "ëª©í‘œ ë‹¨ê°€ ì ˆê°ë¥ (%)ì„ ì„¤ì •í•˜ì„¸ìš”:",
                        min_value=0.0, max_value=float(best_deal['Price_Saving_Pct']),
                        value=float(best_deal['Price_Saving_Pct'] / 2),
                        step=0.5, format="%.1f%%"
                    )
                
                user_total_volume = s_res['user_total_volume']
                user_avg_price = s_res['user_avg_price']
                expected_saving_amount = user_total_volume * user_avg_price * (target_saving_pct / 100)

                with col2:
                    st.metric(
                        label=f"ì˜ˆìƒ ì ˆê° ê¸ˆì•¡ (ì—°ê°„ ìˆ˜ì…ëŸ‰ {user_total_volume:,.0f}KG ê¸°ì¤€)",
                        value=f"${expected_saving_amount:,.0f}"
                    )

                st.markdown("##### **ì¶”ì²œ ëŒ€ì²´ ê³µê¸‰ì²˜ ë¦¬ìŠ¤íŠ¸**")
                st.info("ê³µê¸‰ì²˜ì˜ 'ê°€ê²© ê²½ìŸë ¥'ê³¼ 'ê³µê¸‰ ì•ˆì •ì„±'ì„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ì „ëµì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.")
                
                # ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ë° í‘œì‹œ
                recommended_list = alts[alts['Price_Saving_Pct'] >= target_saving_pct].copy()
                recommended_list.rename(columns={
                    'exporter': 'ìˆ˜ì¶œì—…ì²´', 'Avg_UnitPrice': 'í‰ê·  ë‹¨ê°€ (USD)', 
                    'Price_Saving_Pct': 'ê°€ê²© ê²½ìŸë ¥ (%)', 'Trade_Count': 'ê±°ë˜ ë¹ˆë„ (ê±´)', 
                    'Num_Importers': 'ê±°ë˜ì²˜ ìˆ˜', 'Stability_Score': 'ê³µê¸‰ ì•ˆì •ì„± ì ìˆ˜'
                }, inplace=True)
                
                st.dataframe(
                    recommended_list[['ìˆ˜ì¶œì—…ì²´', 'í‰ê·  ë‹¨ê°€ (USD)', 'ê°€ê²© ê²½ìŸë ¥ (%)', 'ê±°ë˜ ë¹ˆë„ (ê±´)', 'ê±°ë˜ì²˜ ìˆ˜', 'ê³µê¸‰ ì•ˆì •ì„± ì ìˆ˜']],
                    use_container_width=True,
                    column_config={
                        "í‰ê·  ë‹¨ê°€ (USD)": st.column_config.NumberColumn(format="$%.2f"),
                        "ê°€ê²© ê²½ìŸë ¥ (%)": st.column_config.ProgressColumn(
                            format="%.1f%%", min_value=0, max_value=alts['Price_Saving_Pct'].max()
                        ),
                        "ê³µê¸‰ ì•ˆì •ì„± ì ìˆ˜": st.column_config.BarChartColumn(y_min=0, y_max=alts['Stability_Score'].max())
                    },
                    hide_index=True
                )
            st.markdown("---")

# --- ë©”ì¸ ë¡œì§ ì‹¤í–‰ ---
if 'logged_in' not in st.session_state:
    st.session_state['logged_in'] = False

if st.session_state['logged_in']:
    company_data = load_company_data()
    if company_data is not None:
        main_dashboard(company_data)
    else:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•± ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
else:
    login_screen()
