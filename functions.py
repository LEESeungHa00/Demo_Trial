import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
from datetime import datetime
from dateutil.relativedelta import relativedelta
from google.oauth2.service_account import Credentials
from pandas_gbq import read_gbq
import gspread
from zoneinfo import ZoneInfo

# --- í˜ì´ì§€ ì´ˆê¸° ì„¤ì • ---
st.set_page_config(layout="wide", page_title="ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")

# --- API ì‚¬ìš© ë²”ìœ„(Scope) ì •ì˜ ---
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive',
    'https://www.googleapis.com/auth/bigquery'
]

# --- ë°ì´í„° ë¡œë”© (BigQuery) ---
@st.cache_data(ttl=3600)
def load_company_data():
    """Google BigQueryì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=SCOPES)
        project_id = st.secrets["gcp_service_account"]["project_id"]
        table_full_id = f"{project_id}.demo_data.tds_data"
        df = read_gbq(f"SELECT * FROM `{table_full_id}`", project_id=project_id, credentials=creds)
        
        df.columns = [re.sub(r'[^a-z0-9]+', '_', col.lower().strip()) for col in df.columns]
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        for col in ['volume', 'value']:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce')
        df.dropna(subset=['date', 'volume', 'value', 'importer', 'exporter', 'hs_code'], inplace=True)
        df = df[(df['volume'] > 0) & (df['value'] > 0)].copy()
        df['unitprice'] = df['value'] / df['volume']
        Q1, Q3 = df['unitprice'].quantile(0.05), df['unitprice'].quantile(0.95)
        df = df[(df['unitprice'] >= Q1) & (df['unitprice'] <= Q3)]
        return df
    except Exception as e: st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}"); return None

# --- Google Sheets ì €ì¥ ---
def save_to_google_sheets(purchase_df, importer_name, consent):
    """ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì„ ì§€ì •ëœ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=SCOPES)
        client = gspread.authorize(creds)
        spreadsheet = client.open(st.secrets.get("google_sheets", {}).get("spreadsheet_name", "DEMO_app_DB"))
        worksheet_name = st.secrets.get("google_sheets", {}).get("worksheet_name", "Customer_input")
        try:
            worksheet = spreadsheet.worksheet(worksheet_name)
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=1, cols=20)
        save_data_df = purchase_df.copy()
        save_data_df['importer_name'] = importer_name; save_data_df['consent'] = consent
        save_data_df['timestamp'] = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")
        save_data_df['Date'] = pd.to_datetime(save_data_df['Date'])
        save_data_df['Date'] = save_data_df['Date'].dt.strftime('%Y-%m-%d')
        save_data_df = save_data_df.astype(str)
        final_columns = ["Date", "Reported Product Name", "HS-Code", "Origin Country", "Exporter", "Volume", "Value", "Incoterms", "importer_name", "consent", "timestamp"]
        save_data_df = save_data_df[final_columns]
        if not worksheet.get('A1'): worksheet.update([save_data_df.columns.values.tolist()] + save_data_df.values.tolist(), value_input_option='USER_ENTERED')
        else: worksheet.append_rows(save_data_df.values.tolist(), value_input_option='USER_ENTERED')
        #st.toast("ì…ë ¥ ì •ë³´ê°€ Google Sheetì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="âœ…")
        return True
    except gspread.exceptions.APIError as e:
        st.error("Google Sheets API ì˜¤ë¥˜. GCPì—ì„œ API í™œì„±í™” ë° ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        st.json(e.response.json()); return False
    except Exception as e:
        st.error(f"Google Sheets ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"); st.exception(e); return False

# --- ë¶„ì„ í—¬í¼ í•¨ìˆ˜ ---
def clean_text(text):
    if not isinstance(text, str): return ''
    text = text.lower(); text = re.sub(r'\(.*?\)|\[.*?\]', ' ', text); text = re.sub(r'(\d+)\s*(?:y|yo|year|years|old|ë…„ì‚°|ë…„)', r'\1', text); text = re.sub(r'[^a-z0-9\s\uac00-\ud7a3]', ' ', text); text = re.sub(r'\bì‚°\b', ' ', text)
    return ' '.join(text.split())

def assign_quadrant_group(row, x_mean, y_mean):
    is_high_volume = row['total_volume'] >= x_mean; is_high_price = row['price_index'] >= y_mean
    if is_high_volume and is_high_price: return "ë§ˆì¼“ ë¦¬ë”"
    elif not is_high_volume and is_high_price: return "í”„ë¦¬ë¯¸ì—„ ì „ëµ ê·¸ë£¹"
    elif not is_high_volume and not is_high_price: return "íš¨ìœ¨ì  ì†Œì‹± ê·¸ë£¹"
    else: return "ì›ê°€ ìš°ìœ„ ê·¸ë£¹"

def to_excel_col(n): # 0ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆ«ìë¥¼ ë°›ì•„ Aì‚¬, Bì‚¬... Zì‚¬, AAì‚¬... ë“±ìœ¼ë¡œ ë³€í™˜
    name = ""
    while n >= 0:
        name = chr(ord('A') + n % 26) + name
        n = n // 26 - 1
    return name + "ì‚¬"
    
# --- ë©”ì¸ ë¶„ì„ ë¡œì§ ---
def run_all_analysis(user_inputs, full_company_data, selected_products, target_importer_name):
    analysis_result = {"overview": {}, "diagnosis": {}, "timeseries": {}, "positioning": {}, "supply_chain": {}}
    user_total_volume = sum(item['Volume'] for item in user_inputs); user_total_value = sum(item['Value'] for item in user_inputs)
    user_avg_price = user_total_value / user_total_volume if user_total_volume > 0 else 0
    user_input = user_inputs[0]; user_date = pd.to_datetime(user_input['Date'])
    
    hscode = str(user_input.get('HS-Code', ''))
    if hscode:
        hscode_data = full_company_data[full_company_data['hs_code'].astype(str) == hscode].copy()
        if not hscode_data.empty:
            this_year = datetime.now().year; vol_this_year = hscode_data[hscode_data['date'].dt.year == this_year]['volume'].sum(); vol_last_year = hscode_data[hscode_data['date'].dt.year == this_year - 1]['volume'].sum(); price_this_year = hscode_data[hscode_data['date'].dt.year == this_year]['unitprice'].mean(); price_last_year = hscode_data[hscode_data['date'].dt.year == this_year - 1]['unitprice'].mean()
            analysis_result['overview'] = {"hscode": hscode, "this_year": this_year, "vol_this_year": vol_this_year, "vol_last_year": vol_last_year, "price_this_year": price_this_year, "price_last_year": price_last_year, "freq_this_year": len(hscode_data[hscode_data['date'].dt.year == this_year]), "product_composition": hscode_data.groupby('reported_product_name')['value'].sum().nlargest(10)}

    analysis_data = full_company_data[full_company_data['reported_product_name'].isin(selected_products)].copy()
    if analysis_data.empty: return analysis_result
    
    month_data = analysis_data[analysis_data['date'].dt.to_period('M') == user_date.to_period('M')]
    month_avg_price = 0
    if not month_data.empty:
        month_avg_price = month_data['unitprice'].mean(); price_percentile = (month_data['unitprice'] < user_avg_price).mean() * 100
        top_10_percent_price = month_data['unitprice'].quantile(0.10); potential_savings = (user_avg_price - top_10_percent_price) * user_total_volume
        analysis_result['diagnosis'] = {"user_price": user_avg_price, "market_avg_price": month_avg_price, "percentile": price_percentile, "top_10_price": top_10_percent_price, "potential_savings": potential_savings if potential_savings > 0 else 0}
        
    monthly_avg = analysis_data.set_index('date')['unitprice'].resample('M').mean().reset_index()
    analysis_result['timeseries'] = {"all_trades": analysis_data[['date', 'unitprice', 'volume']], "monthly_avg": monthly_avg, "current_transaction": {'date': user_date, 'unitprice': user_avg_price, 'volume': user_total_volume}}
        
    analysis_data['month'] = analysis_data['date'].dt.to_period('M')
    monthly_benchmarks = analysis_data.groupby('month')['unitprice'].transform('mean')
    analysis_data['price_index'] = analysis_data['unitprice'] / monthly_benchmarks
    importer_stats = analysis_data.groupby('importer').agg(total_value=('value', 'sum'), total_volume=('volume', 'sum'), trade_count=('value', 'count'), price_index=('price_index', 'mean')).reset_index().sort_values('total_value', ascending=False).reset_index(drop=True)
    
    volume_mean = importer_stats['total_volume'].mean(); price_index_mean = 1.0
    importer_stats['quadrant_group'] = importer_stats.apply(assign_quadrant_group, axis=1, args=(volume_mean, price_index_mean))
    importer_stats['cum_share'] = importer_stats['total_value'].cumsum() / importer_stats['total_value'].sum()
    market_leaders = importer_stats[importer_stats['cum_share'] <= 0.7]
    try:
        target_rank = importer_stats[importer_stats['importer'] == target_importer_name].index[0]; rank_margin = max(1, int(len(importer_stats) * 0.1)); direct_peers = importer_stats.iloc[max(0, target_rank - rank_margin):min(len(importer_stats), target_rank + rank_margin + 1)]
    except IndexError: direct_peers = pd.DataFrame()
    price_achievers = importer_stats[importer_stats['price_index'] <= importer_stats['price_index'].quantile(0.15)]
    current_transaction_price_index = user_avg_price / month_avg_price if month_avg_price > 0 else 1.0
    current_tx_normalized = {'total_volume': user_total_volume, 'price_index': current_transaction_price_index}
    analysis_result['positioning'] = {"importer_stats": importer_stats, "target_stats": importer_stats[importer_stats['importer'] == target_importer_name], "rule_based_groups": {"ì‹œì¥ ì„ ë„ ê·¸ë£¹": market_leaders, "ìœ ì‚¬ ê·œëª¨ ê²½ìŸ ê·¸ë£¹": direct_peers, "ìµœì €ê°€ ë‹¬ì„± ê·¸ë£¹": price_achievers}, "current_transaction_normalized": current_tx_normalized}
    
    alternative_suppliers = analysis_data[(analysis_data['exporter'].str.upper() != user_input['Exporter'].upper()) & (analysis_data['unitprice'] < user_avg_price)]
    if not alternative_suppliers.empty:
        supplier_analysis = alternative_suppliers.groupby('exporter').agg(avg_unitprice=('unitprice', 'mean'), trade_count=('value', 'count'), num_importers=('importer', 'nunique')).reset_index().sort_values('avg_unitprice')
        supplier_analysis['price_saving_pct'] = (1 - supplier_analysis['avg_unitprice'] / user_avg_price) * 100
        supplier_analysis['stability_score'] = np.log1p(supplier_analysis['trade_count']) + np.log1p(supplier_analysis['num_importers'])
        if len(supplier_analysis) >= 3:
            low_q, high_q = supplier_analysis['stability_score'].quantile(0.33), supplier_analysis['stability_score'].quantile(0.67)
            conditions = [supplier_analysis['stability_score'] <= low_q, (supplier_analysis['stability_score'] > low_q) & (supplier_analysis['stability_score'] < high_q), supplier_analysis['stability_score'] >= high_q]; ratings = ['í•˜', 'ì¤‘', 'ìƒ']
            supplier_analysis['stability_rank'] = np.select(conditions, ratings, default='ì¤‘')
        else: supplier_analysis['stability_rank'] = 'ì¤‘'
        analysis_result['supply_chain'] = {"user_avg_price": user_avg_price, "user_total_volume": user_total_volume, "alternatives": supplier_analysis}
    return analysis_result

# --- UI ì»´í¬ë„ŒíŠ¸ ---
def login_screen():
    st.title("ğŸ” ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    with st.form("login_form"):
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.form_submit_button("ì ‘ì†í•˜ê¸°"):
            if password == st.secrets.get("app_secrets", {}).get("password", "tridgeDemo_2025"):
                st.session_state['logged_in'] = True; st.rerun()
            else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def main_dashboard(company_data):
    st.title("ğŸ“ˆ ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    with st.expander("STEP 1: ë¶„ì„ ì •ë³´ ì…ë ¥", expanded='analysis_groups' not in st.session_state):
        importer_name = st.text_input("1. ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="importer_name_input").upper()
        if 'rows' not in st.session_state: st.session_state['rows'] = [{'id': 1}]
        header_cols = st.columns([1.5, 3, 1, 2, 2, 1, 1, 1, 0.5]); headers = ["ìˆ˜ì…ì¼", "ì œí’ˆ ìƒì„¸ëª…", "HS-CODE", "ì›ì‚°ì§€", "ìˆ˜ì¶œì—…ì²´", "ìˆ˜ì… ì¤‘ëŸ‰(KG)", "ì´ ìˆ˜ì…ê¸ˆì•¡(USD)", "Incoterms", "ì‚­ì œ"]
        for col, header in zip(header_cols, headers): col.markdown(f"**{header}**")
        for i, row in enumerate(st.session_state.rows):
            key_suffix = f"_{row['id']}"; cols = st.columns([1.5, 3, 1, 2, 2, 1, 1, 1, 0.5])
            st.session_state[f'date{key_suffix}'] = cols[0].date_input(f"date_widget{key_suffix}", value=st.session_state.get(f'date{key_suffix}', datetime.now().date()), key=f"date_widget_k{key_suffix}", label_visibility="collapsed")
            st.session_state[f'product_name{key_suffix}'] = cols[1].text_input(f"product_name_widget{key_suffix}", value=st.session_state.get(f'product_name{key_suffix}', ''), key=f"product_name_widget_k{key_suffix}", label_visibility="collapsed")
            st.session_state[f'hscode{key_suffix}'] = cols[2].text_input(f"hscode_widget{key_suffix}", max_chars=10, value=st.session_state.get(f'hscode{key_suffix}', ''), key=f"hscode_widget_k{key_suffix}", label_visibility="collapsed")
            origin_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['export_country'].unique()); origin_val_selected = cols[3].selectbox(f"origin_widget{key_suffix}", origin_options, index=origin_options.index(st.session_state.get(f'origin_selected{key_suffix}', '')) if st.session_state.get(f'origin_selected{key_suffix}') in origin_options else 0, key=f"origin_widget_k{key_suffix}", label_visibility="collapsed", format_func=lambda x: 'ì„ íƒ' if x == '' else x)
            st.session_state[f'origin_selected{key_suffix}'] = origin_val_selected
            if origin_val_selected == 'ì§ì ‘ ì…ë ¥': st.session_state[f'origin{key_suffix}'] = cols[3].text_input("custom_origin", value=st.session_state.get(f'origin{key_suffix}', ''), key=f"custom_origin_k{key_suffix}", label_visibility="collapsed", placeholder="ì›ì‚°ì§€ ì§ì ‘ ì…ë ¥")
            else: st.session_state[f'origin{key_suffix}'] = origin_val_selected
            exporter_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['exporter'].unique()); exporter_val_selected = cols[4].selectbox(f"exporter_widget{key_suffix}", exporter_options, index=exporter_options.index(st.session_state.get(f'exporter_selected{key_suffix}', '')) if st.session_state.get(f'exporter_selected{key_suffix}') in exporter_options else 0, key=f"exporter_widget_k{key_suffix}", label_visibility="collapsed", format_func=lambda x: 'ì„ íƒ' if x == '' else x)
            st.session_state[f'exporter_selected{key_suffix}'] = exporter_val_selected
            if exporter_val_selected == 'ì§ì ‘ ì…ë ¥': st.session_state[f'exporter{key_suffix}'] = cols[4].text_input("custom_exporter", value=st.session_state.get(f'exporter{key_suffix}', ''), key=f"custom_exporter_k{key_suffix}", label_visibility="collapsed", placeholder="ìˆ˜ì¶œì—…ì²´ ì§ì ‘ ì…ë ¥")
            else: st.session_state[f'exporter{key_suffix}'] = exporter_val_selected
            st.session_state[f'volume{key_suffix}'] = cols[5].number_input(f"volume_widget{key_suffix}", min_value=0.01, format="%.2f", value=st.session_state.get(f'volume{key_suffix}', 1000.0), key=f"volume_widget_k{key_suffix}", label_visibility="collapsed")
            st.session_state[f'value{key_suffix}'] = cols[6].number_input(f"value_widget{key_suffix}", min_value=0.01, format="%.2f", value=st.session_state.get(f'value{key_suffix}', 10000.0), key=f"value_widget_k{key_suffix}", label_visibility="collapsed")
            st.session_state[f'incoterms{key_suffix}'] = cols[7].selectbox(f"incoterms_widget{key_suffix}", ["FOB", "CFR", "CIF", "EXW", "DDP", "ê¸°íƒ€"], index=["FOB", "CFR", "CIF", "EXW", "DDP", "ê¸°íƒ€"].index(st.session_state.get(f'incoterms{key_suffix}', 'FOB')), key=f"incoterms_widget_k{key_suffix}", label_visibility="collapsed")
            if len(st.session_state.rows) > 1 and cols[8].button("ì‚­ì œ", key=f"delete{key_suffix}"): st.session_state.rows.pop(i); st.rerun()
        if st.button("â• ë‚´ì—­ ì¶”ê°€í•˜ê¸°"):
            new_id = max(row['id'] for row in st.session_state.rows) + 1 if st.session_state.rows else 1; st.session_state.rows.append({'id': new_id}); st.rerun()
        st.markdown("---")
        consent = st.checkbox("ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì…ë ¥í•œ ë°ì´í„°ê°€ í™œìš©ë˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤.", value=st.session_state.get('consent', True), key='consent_widget'); st.session_state['consent'] = consent
        if st.button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True):
            all_input_data = []; is_valid = True
            if not importer_name: st.error("âš ï¸ [ì…ë ¥ ì˜¤ë¥˜] ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."); is_valid = False
            if not consent: st.warning("âš ï¸ ì •ë³´ í™œìš© ë™ì˜ì— ì²´í¬í•´ì£¼ì„¸ìš”."); is_valid = False
            for i, row in enumerate(st.session_state.rows):
                key_suffix = f"_{row['id']}"; entry = { "Date": st.session_state.get(f'date{key_suffix}'), "Reported Product Name": st.session_state.get(f'product_name{key_suffix}'), "HS-Code": st.session_state.get(f'hscode{key_suffix}'), "Origin Country": st.session_state.get(f'origin{key_suffix}'), "Exporter": st.session_state.get(f'exporter{key_suffix}'), "Volume": st.session_state.get(f'volume{key_suffix}'), "Value": st.session_state.get(f'value{key_suffix}'), "Incoterms": st.session_state.get(f'incoterms{key_suffix}')}
                all_input_data.append(entry)
                if not all([entry['Reported Product Name'], entry['HS-Code'], entry['Origin Country'], entry['Exporter']]): st.error(f"âš ï¸ [ì…ë ¥ ì˜¤ë¥˜] {i+1}ë²ˆì§¸ ì¤„ì˜ í•„ìˆ˜ í•­ëª©ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”."); is_valid = False
            if is_valid:
                with st.spinner('ì…ë ¥ ë°ì´í„°ë¥¼ DBì— ë°˜ì˜í•´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...'):
                    purchase_df = pd.DataFrame(all_input_data)
                    if save_to_google_sheets(purchase_df, importer_name, consent):
                        purchase_df['cleaned_name'] = purchase_df['Reported Product Name'].apply(clean_text)
                        agg_funcs = {'Volume': 'sum', 'Value': 'sum', 'Reported Product Name': 'first', 'HS-Code': 'first', 'Exporter': 'first', 'Date':'first', 'Origin Country':'first', 'Incoterms':'first'}
                        aggregated_purchase_df = purchase_df.groupby('cleaned_name', as_index=False).agg(agg_funcs)
                        analysis_groups = []
                        company_data['cleaned_name'] = company_data['reported_product_name'].apply(clean_text)
                        for _, row in aggregated_purchase_df.iterrows():
                            entry = row.to_dict(); user_tokens = set(entry['cleaned_name'].split()); is_match = lambda name: user_tokens.issubset(set(str(name).split())); matched_df = company_data[company_data['cleaned_name'].apply(is_match)]; matched_products = sorted(matched_df['reported_product_name'].unique().tolist()); result = run_all_analysis([entry], company_data, matched_products, importer_name)
                            analysis_groups.append({"user_input": entry, "matched_products": matched_products, "selected_products": matched_products, "result": result})
                        st.session_state['importer_name_result'] = importer_name; st.session_state['analysis_groups'] = analysis_groups
                        st.success("ë¶„ì„ ì™„ë£Œ!"); st.rerun()
    
    if 'analysis_groups' in st.session_state:
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        processed_hscodes = []
        for group in st.session_state.analysis_groups:
            overview_res = group['result'].get('overview')
            if overview_res and overview_res['hscode'] not in processed_hscodes:
                st.subheader(f"ğŸ“ˆ HS-Code {overview_res['hscode']} ì‹œì¥ ê°œìš”")
                o = overview_res; cols = st.columns(3)
                vol_yoy = (o['vol_this_year'] - o['vol_last_year']) / o['vol_last_year'] if o['vol_last_year'] > 0 else np.nan; price_yoy = (o['price_this_year'] - o['price_last_year']) / o['price_last_year'] if o['price_last_year'] > 0 else np.nan
                cols[0].metric(f"{o['this_year']}ë…„ ìˆ˜ì… ì¤‘ëŸ‰ (KG)", f"{o['vol_this_year']:,.0f}", f"{vol_yoy:.1%}" if pd.notna(vol_yoy) else "N/A", delta_color="inverse")
                cols[1].metric(f"{o['this_year']}ë…„ í‰ê·  ë‹¨ê°€ (USD/KG)", f"${o['price_this_year']:.2f}", f"{price_yoy:.1%}" if pd.notna(price_yoy) else "N/A", delta_color="inverse")
                cols[2].metric(f"{o['this_year']}ë…„ ì´ ìˆ˜ì… ê±´ìˆ˜", f"{o['freq_this_year']:,} ê±´")
                if not o['product_composition'].empty:
                    pie_fig = px.pie(o['product_composition'], names=o['product_composition'].index, values=o['product_composition'].values, title='<b>ìƒìœ„ 10ê°œ ì œí’ˆ êµ¬ì„± (ìˆ˜ì… ê¸ˆì•¡ ê¸°ì¤€)</b>', hole=0.3)
                    pie_fig.update_traces(textposition='inside', textinfo='percent+label'); st.plotly_chart(pie_fig, use_container_width=True)
                st.markdown("---"); processed_hscodes.append(overview_res['hscode'])

        for i, group in enumerate(st.session_state.analysis_groups):
            product_name = group['user_input']['Reported Product Name']; st.subheader(f"ë¶„ì„ ê·¸ë£¹: \"{product_name}\"")
            result, diag_res, ts_res, p_res, s_res = group['result'], group['result'].get('diagnosis'), group['result'].get('timeseries'), group['result'].get('positioning'), group['result'].get('supply_chain')
            
            st.markdown("#### PART 1. ì´ë²ˆ ê±°ë˜ ê²½ìŸë ¥ ì§„ë‹¨ ìš”ì•½")
            if diag_res:
                price_diff = (diag_res['user_price'] / diag_res['market_avg_price'] - 1) * 100 if diag_res['market_avg_price'] > 0 else 0
                cols = st.columns(3); cols[0].metric("ì´ë²ˆ ê±°ë˜ ë‹¨ê°€", f"${diag_res['user_price']:.2f}", f"{price_diff:.1f}% (ë™ì›” í‰ê·  ëŒ€ë¹„)", delta_color="inverse")
                cols[1].metric("ë™ì›” ë‚´ ê°€ê²© ë°±ë¶„ìœ„", f"ìƒìœ„ {100-diag_res['percentile']:.0f}%", help="100%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë™ì›” ì‹œì¥ì—ì„œ ì €ë ´í•˜ê²Œ êµ¬ë§¤í•œ ê±°ë˜ì…ë‹ˆë‹¤.")
                cols[2].metric("ì˜ˆìƒ ì¶”ê°€ ì ˆê° ê°€ëŠ¥ ê¸ˆì•¡", f"${diag_res['potential_savings']:,.0f} ë‚´ì™¸", help=f"ë™ì›” ìƒìœ„ 10% í‰ê· ê°€(${diag_res['top_10_price']:.2f}) ê¸°ì¤€")
            else: st.info("ì´ë²ˆ ê±°ë˜ì™€ ë™ì¼í•œ ì›”ì˜ ì‹œì¥ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì§„ë‹¨ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.markdown("---")

            st.markdown("#### PART 2. ì‹œê³„ì—´ ì‹œì¥ ë™í–¥ ë° ê±°ë˜ ìœ„ì¹˜")
            if ts_res and not ts_res['all_trades'].empty:
                fig_ts = go.Figure()
                all_trades_df = ts_res['all_trades'].copy()
                target_name = st.session_state.get('importer_name_result', '')
            
                # --- ìµëª…í™” ë¡œì§ ì‹œì‘ ---
                # 1. ì‹œê³„ì—´ ë°ì´í„°ì— ìˆëŠ” ëª¨ë“  ê³ ìœ  ìˆ˜ì…ì‚¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                unique_importers_ts = all_trades_df['importer'].unique()
                
                # 2. ê° ìˆ˜ì…ì‚¬ ì´ë¦„ì— ìµëª…(Aì‚¬, Bì‚¬...)ì„ ì§ì§€ì–´ì£¼ëŠ” ë”•ì…”ë„ˆë¦¬(ì§€ë„)ë¥¼ ë§Œë“­ë‹ˆë‹¤.
                #    (ë‹¨, ê·€ì‚¬ì˜ ì´ë¦„ì€ ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤.)
                anonymity_map_ts = {name: to_excel_col(i) for i, name in enumerate(unique_importers_ts) if name != target_name}
                anonymity_map_ts[target_name] = target_name
                
                # 3. ìœ„ì—ì„œ ë§Œë“  ì§€ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ 'Anonymized_Importer'ë¼ëŠ” ìƒˆ ì—´ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
                all_trades_df['Anonymized_Importer'] = all_trades_df['importer'].map(anonymity_map_ts)
                # --- ìµëª…í™” ë¡œì§ ë ---
            
                # ì°¨íŠ¸ì˜ íšŒìƒ‰ ë²„ë¸”ì„ ê·¸ë¦´ ë•Œ, ìµëª…í™”ëœ ì´ë¦„(Anonymized_Importer)ì„ hover ì •ë³´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                log_volume = np.log1p(all_trades_df['volume'])
                # ... (ë²„ë¸” ì‚¬ì´ì¦ˆ ê³„ì‚°) ...
                fig_ts.add_trace(go.Scatter(
                    x=all_trades_df['date'], 
                    y=all_trades_df['unitprice'], 
                    mode='markers', 
                    marker=dict(size=bubble_size, color='lightgray', opacity=0.6), 
                    name='ê³¼ê±° ì‹œì¥ ê±°ë˜', 
                    text=all_trades_df['Anonymized_Importer'], # ìµëª…í™”ëœ ì´ë¦„ ì‚¬ìš©
                    hovertemplate='<b>%{text}</b><br>ë‹¨ê°€: $%{y:,.2f}<extra></extra>' # hover ì‹œ ìµëª… ì´ë¦„ í‘œì‹œ
                ))
            st.markdown("---")

            # --- main_dashboard í•¨ìˆ˜ ë‚´ PART 3 ì‹œê°í™” ë¶€ë¶„ ---
            
            st.markdown("#### PART 3. ê²½ìŸ í™˜ê²½ ë° ì „ëµ ë¶„ì„")
            if not p_res or p_res['importer_stats'].empty: st.info("ê²½ìŸ í™˜ê²½ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."); continue
            
            # 3-1. ì‹œì¥ ë‚´ ì „ëµì  ìœ„ì¹˜ (ì‹œì  ì •ê·œí™”)
            col1, col2 = st.columns([10,1])
            col1.markdown("##### **3-1. ì‹œì¥ ë‚´ ì „ëµì  ìœ„ì¹˜ (ì‹œì  ì •ê·œí™”)**")
            with col2:
                with st.popover("â„¹ï¸"): st.markdown("""**ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜ë€?**\nê³„ì ˆì„±ì´ë‚˜ ì‹œì¥ íŠ¸ë Œë“œ ë“± ì‹œì  ìš”ì¸ì„ ì œê±°í•œ ìˆœìˆ˜í•œ ê°€ê²© ê²½ìŸë ¥ì…ë‹ˆë‹¤.\n- **ê³„ì‚°ì‹:** `ê°œë³„ ê±°ë˜ ë‹¨ê°€ / í•´ë‹¹ ì›”ì˜ ì‹œì¥ í‰ê·  ë‹¨ê°€`\n- **1.0 ë¯¸ë§Œ:** ì‹œì¥ í‰ê· ë³´ë‹¤ ì €ë ´í•˜ê²Œ êµ¬ë§¤\n- **1.0 ì´ˆê³¼:** ì‹œì¥ í‰ê· ë³´ë‹¤ ë¹„ì‹¸ê²Œ êµ¬ë§¤""")
            
            importer_stats = p_res['importer_stats']
            target_name = st.session_state.get('importer_name_result', '')
            
            # ì°¨íŠ¸ì— í‘œì‹œí•  íšŒì‚¬ ëª©ë¡(plot_df) ìƒì„±
            try:
                target_rank = importer_stats[importer_stats['importer'] == target_name].index[0]
                rank_margin = max(1, int(len(importer_stats) * 0.1))
                direct_peers = importer_stats.iloc[max(0, target_rank - rank_margin):min(len(importer_stats), target_rank + rank_margin + 1)]
            except IndexError:
                direct_peers = pd.DataFrame()
            plot_df = pd.concat([importer_stats.head(5), direct_peers, p_res['target_stats']]).drop_duplicates().reset_index(drop=True)
            
            # ìµëª…í™” ì´ë¦„ ìƒì„±
            plot_df['Anonymized_Importer'] = [to_excel_col(j) if imp != target_name else target_name for j, imp in enumerate(plot_df['importer'])]
            
            # (ìˆ˜ì •) ë²„ë¸” í¬ê¸° ê³„ì‚° ê¸°ì¤€ì„ plot_dfë¡œ ë³€ê²½í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
            log_values = np.log1p(plot_df['total_value'])
            min_size, max_size = 15, 80
            if log_values.max() > log_values.min():
                plot_df['size'] = min_size + ((log_values - log_values.min()) / (log_values.max() - log_values.min())) * (max_size - min_size)
            else:
                plot_df['size'] = [min_size] * len(plot_df)
            
            # ì°¨íŠ¸ ìƒì„±
            x_mean = importer_stats['total_volume'].mean() # ì‹œì¥ í‰ê· ì€ ì „ì²´ ë°ì´í„° ê¸°ì¤€ì´ë¯€ë¡œ importer_stats ì‚¬ìš© (ì •ìƒ)
            y_mean = 1.0
            fig_pos = go.Figure()
            
            # (ìˆ˜ì •) ë°ì´í„° ì°¸ì¡°ë¥¼ plot_dfë¡œ ë³€ê²½í•˜ê³ , hover ì •ë³´ì— ìµëª…í™”ëœ ì´ë¦„ ì‚¬ìš©
            competitors = plot_df[plot_df['importer'] != target_name]
            fig_pos.add_trace(go.Scatter(
                x=competitors['total_volume'], y=competitors['price_index'], 
                mode='markers', marker=dict(size=competitors['size'], color='#BDBDBD', opacity=0.5), 
                text=competitors['Anonymized_Importer'], # ìµëª… ì´ë¦„ ì‚¬ìš©
                hovertemplate='<b>%{text}</b><br>ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜: %{y:.2f}<extra></extra>'
            ))
            
            # (ìˆ˜ì •) ë°ì´í„° ì°¸ì¡°ë¥¼ plot_dfë¡œ ë³€ê²½í•˜ê³ , hover ì •ë³´ì— ìµëª…í™”ëœ ì´ë¦„ ì‚¬ìš©
            target_df = plot_df[plot_df['importer'] == target_name]
            if not target_df.empty:
                fig_pos.add_trace(go.Scatter(
                    x=target_df['total_volume'], y=target_df['price_index'], 
                    mode='markers', marker=dict(size=target_df['size'], color='#FF4B4B', opacity=1.0, line=dict(width=2, color='black')), 
                    name='ê·€ì‚¬(ê³¼ê±° í‰ê· )', 
                    text=target_df['Anonymized_Importer'], # ìµëª… ì´ë¦„ ì‚¬ìš© (ì‹¤ì œë¡œëŠ” ê·€ì‚¬ ì´ë¦„)
                    hovertemplate='<b>%{text} (í‰ê· )</b><br>ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜: %{y:.2f}<extra></extra>'
                ))
            
            current_tx_norm = p_res.get('current_transaction_normalized')
            if current_tx_norm:
                fig_pos.add_trace(go.Scatter(
                    x=[current_tx_norm['total_volume']], y=[current_tx_norm['price_index']], 
                    mode='markers', marker=dict(symbol='star', color='black', size=20, line=dict(color='white', width=2)), 
                    name='ì´ë²ˆ ê±°ë˜', 
                    hovertemplate='<b>ì´ë²ˆ ê±°ë˜</b><br>ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜: %{y:.2f}<extra></extra>'
                ))
            
            fig_pos.add_vline(x=x_mean, line_dash="dash", line_color="gray")
            fig_pos.add_hline(y=y_mean, line_dash="dash", line_color="gray")
            fig_pos.update_layout(title="<b>ìˆ˜ì…ì‚¬ í¬ì§€ì…”ë‹ ë§µ (ì‹œê¸° ë³´ì •)</b>", xaxis_title="ì´ ìˆ˜ì… ì¤‘ëŸ‰ (KG, Log Scale)", yaxis_title="ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜ (1.0 = ì‹œì¥ í‰ê· )", showlegend=False, xaxis_type="log")
            st.plotly_chart(fig_pos, use_container_width=True)

            col1, col2 = st.columns([10,1]); col1.markdown("##### **3-2. ì‹¤ì§ˆ ê²½ìŸ ê·¸ë£¹ê³¼ì˜ ë¹„êµ**")
            with col2:
                with st.popover("â„¹ï¸"): st.markdown("""**ê·¸ë£¹ ë¶„ë¥˜ ê¸°ì¤€:**\n- **ì‹œì¥ ì„ ë„ ê·¸ë£¹:** ìˆ˜ì… ê¸ˆì•¡ ê¸°ì¤€ ëˆ„ì  70% ì°¨ì§€\n- **ìœ ì‚¬ ê·œëª¨ ê²½ìŸ ê·¸ë£¹:** ê·€ì‚¬ ìˆœìœ„ ê¸°ì¤€ ìƒí•˜ Â±10%\n- **ìµœì €ê°€ ë‹¬ì„± ê·¸ë£¹:** ì‹œê¸° ë³´ì •ëœ 'ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜' í•˜ìœ„ 15%\n *ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ì¡°ê±´ì— ë§ëŠ” ê²½ìŸì‚¬ê°€ ì—†ìœ¼ë©´ í•´ë‹¹ ê·¸ë£¹ì€ ë°•ìŠ¤ í”Œë¡¯ì— í‘œì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""")
            rb_groups = p_res['rule_based_groups']; group_data = []
            for name, df in rb_groups.items():
                if not df.empty: 
                    df_copy = df.copy()
                    df_copy['group_name'] = name
                    group_data.append(df_copy[['group_name', 'price_index']])
            if group_data:
                plot_df_box = pd.concat(group_data)
                fig_box = px.box(plot_df_box, x='group_name', y='price_index', title="<b>ì£¼ìš” ê²½ìŸ ê·¸ë£¹ë³„ ê°€ê²© ê²½ìŸë ¥ ë¶„í¬</b>", points='all', labels={'group_name': 'ê²½ìŸ ê·¸ë£¹ ìœ í˜•', 'price_index': 'ê°€ê²© ê²½ìŸë ¥ ì§€ìˆ˜'})
                if not p_res['target_stats'].empty: fig_box.add_hline(y=p_res['target_stats']['price_index'].iloc[0], line_dash="dot", line_color="orange", annotation_text="ê·€ì‚¬ í‰ê· ")
                if current_tx_norm: fig_box.add_hline(y=current_tx_norm['price_index'], line_dash="dash", line_color="blue", annotation_text="ì´ë²ˆ ê±°ë˜")
                st.plotly_chart(fig_box, use_container_width=True)
            st.markdown("---")

            st.markdown("#### PART 4. ê³µê¸‰ë§ ë¶„ì„ ë° ë¹„ìš© ì ˆê° ì‹œë®¬ë ˆì´ì…˜")
            if not s_res or s_res['alternatives'].empty: st.info("í˜„ì¬ ê±°ë˜ ì¡°ê±´ë³´ë‹¤ ë” ì €ë ´í•œ ëŒ€ì•ˆ ê³µê¸‰ì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                alts, best_deal = s_res['alternatives'], s_res['alternatives'].iloc[0]
                num_alternatives = len(alts)
                st.success(f"**ë¹„ìš© ì ˆê° ê¸°íšŒ í¬ì°©!** í˜„ì¬ ê±°ë˜ì²˜ë³´ë‹¤ **ìµœëŒ€ {best_deal['price_saving_pct']:.1f}%** ì €ë ´í•œ ëŒ€ì²´ ê±°ë˜ì²˜ê°€ **{num_alternatives}ê°œ** ì¡´ì¬í•©ë‹ˆë‹¤.")
                col1, col2 = st.columns(2); target_saving_pct = col1.slider("ëª©í‘œ ë‹¨ê°€ ì ˆê°ë¥ (%)", 0.0, float(best_deal['price_saving_pct']), float(best_deal['price_saving_pct'] / 2), 0.5, "%.1f%%", key=f"slider_{i}"); expected_saving = s_res['user_total_volume'] * s_res['user_avg_price'] * (target_saving_pct / 100); col2.metric(f"ì˜ˆìƒ ì ˆê°ì•¡ (ìˆ˜ì…ëŸ‰ {s_res['user_total_volume']:,.0f}KG ê¸°ì¤€)", f"${expected_saving:,.0f}")
                
                col1_supply, col2_supply = st.columns([10,1])
                with col1_supply: st.markdown("##### **ì¶”ì²œ ëŒ€ì²´ ê³µê¸‰ì²˜ ë¦¬ìŠ¤íŠ¸**")
                with col2_supply:
                    with st.popover("â„¹ï¸"):
                        st.markdown("""**ê³µê¸‰ ì•ˆì •ì„± ê¸°ì¤€:**\në°œê²¬ëœ ëŒ€ì²´ ê³µê¸‰ì²˜ë“¤ì˜ 'ê±°ë˜ ë¹ˆë„'ì™€ 'ê±°ë˜ì²˜ ìˆ˜'ë¥¼ ì¢…í•©í•˜ì—¬ ê³„ì‚°ëœ ì•ˆì •ì„± ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ í‰ê°€ë©ë‹ˆë‹¤.\n- **ìƒ:** ìƒìœ„ 33%\n- **ì¤‘:** ì¤‘ê°„ 33%\n- **í•˜:** í•˜ìœ„ 33%""")
                
                recommended_list = alts[alts['price_saving_pct'] >= target_saving_pct].copy()
                recommended_list.reset_index(drop=True, inplace=True); recommended_list['ìˆœë²ˆ'] = recommended_list.index + 1
                recommended_list.rename(columns={'avg_unitprice': 'í‰ê·  ë‹¨ê°€', 'price_saving_pct': 'ê°€ê²© ê²½ìŸë ¥(%)', 'trade_count': 'ê±°ë˜ ë¹ˆë„', 'num_importers': 'ê±°ë˜ ìˆ˜ì…ì‚¬ ê°œìˆ˜', 'stability_rank': 'ê³µê¸‰ ì•ˆì •ì„±'}, inplace=True)
                st.dataframe(recommended_list[['ìˆœë²ˆ', 'í‰ê·  ë‹¨ê°€', 'ê°€ê²© ê²½ìŸë ¥(%)', 'ê±°ë˜ ë¹ˆë„', 'ê±°ë˜ ìˆ˜ì…ì‚¬ ê°œìˆ˜', 'ê³µê¸‰ ì•ˆì •ì„±']], use_container_width=True, 
                             column_config={"í‰ê·  ë‹¨ê°€": st.column_config.NumberColumn(format="$%.2f"), "ê°€ê²© ê²½ìŸë ¥(%)": st.column_config.ProgressColumn(format="%.1f%%", min_value=0, max_value=alts['price_saving_pct'].max())}, hide_index=True)
            st.markdown("---")

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False
if not st.session_state['logged_in']:
    login_screen()
else:
    company_data = load_company_data()
    if company_data is not None:
        main_dashboard(company_data)
    else:
        st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
