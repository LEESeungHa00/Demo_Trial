import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from google.oauth2.service_account import Credentials
from pandas_gbq import read_gbq
import gspread
from zoneinfo import ZoneInfo

# --- í˜ì´ì§€ ì´ˆê¸° ì„¤ì • ---
st.set_page_config(layout="wide", page_title="ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")

# --- ë°ì´í„° ë¡œë”© (BigQuery) ---
@st.cache_data(ttl=3600)
def load_company_data():
    """Google BigQueryì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"])
        project_id = st.secrets["gcp_service_account"]["project_id"]
        # ì‹¤ì œ í…Œì´ë¸”ëª…ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”. ì˜ˆ: "your_dataset.your_table"
        table_full_id = f"{project_id}.demo_data.tds_data"
        df = read_gbq(f"SELECT * FROM `{table_full_id}`", project_id=project_id, credentials=creds)

        if df.empty:
            st.error("BigQueryì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ì§€ë§Œ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        # ì§€ëŠ¥í˜• ì»¬ëŸ¼ëª… ì •ì œ
        df.columns = [re.sub(r'[^a-z0-9]+', '_', col.lower().strip()) for col in df.columns]

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['date', 'volume', 'value', 'reported_product_name', 'export_country', 'exporter', 'importer', 'hs_code']
        if not all(col in df.columns for col in required_cols):
            st.error(f"BigQuery í…Œì´ë¸”ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (í•„ìˆ˜: {required_cols})")
            st.info(f"ì‹¤ì œ ì»¬ëŸ¼ëª…: {df.columns.tolist()}")
            return None

        # ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ì •ì œ
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        for col in ['volume', 'value']:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(r'[^\d.]', '', regex=True), errors='coerce')

        df.dropna(subset=['date', 'volume', 'value', 'importer', 'exporter'], inplace=True)
        df = df[(df['volume'] > 0) & (df['value'] > 0)].copy()

        # ë‹¨ê°€ ê³„ì‚° ë° ì´ìƒì¹˜ ì œê±° (IQR ë°©ì‹)
        df['unitprice'] = df['value'] / df['volume']
        Q1 = df['unitprice'].quantile(0.25)
        Q3 = df['unitprice'].quantile(0.75)
        IQR = Q3 - Q1
        df = df[~((df['unitprice'] < (Q1 - 1.5 * IQR)) | (df['unitprice'] > (Q3 + 1.5 * IQR)))]

        return df if not df.empty else None
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("Streamlit Secretsì˜ 'gcp_service_account' ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

# --- Google Sheets ì €ì¥ ---
def save_to_google_sheets(data_to_save):
    """ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ë¥¼ ì§€ì •ëœ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"])
        client = gspread.authorize(creds)
        
        spreadsheet_name = st.secrets.get("google_sheets", {}).get("spreadsheet_name", "DEMO_app_DB")
        worksheet_name = st.secrets.get("google_sheets", {}).get("worksheet_name", "Customer_input")

        sheet = client.open(spreadsheet_name).worksheet(worksheet_name)
        
        # í—¤ë”ê°€ ë¹„ì–´ìˆì„ ê²½ìš°, í—¤ë” ì¶”ê°€
        if not sheet.get_all_values():
            header = ["Date", "Reported Product Name", "HS-Code", "Export Country", "Exporter",
                      "Volume(KG)", "Value(USD)", "Incoterms", "Importer", "IS_Agreed", "Input_time"]
            sheet.append_row(header)
            
        sheet.append_row(data_to_save, value_input_option='USER_ENTERED')
        return True
    except Exception as e:
        st.error(f"Google Sheets ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.warning("Google Sheets APIê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€, ì„œë¹„ìŠ¤ ê³„ì •ì— í¸ì§‘ì ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return False

# --- ë¶„ì„ í—¬í¼ í•¨ìˆ˜ ---
def clean_text(text):
    """ì œí’ˆëª… í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•©ë‹ˆë‹¤."""
    if not isinstance(text, str): return ''
    text = text.lower()
    text = re.sub(r'\(.*?\)|\[.*?\]', ' ', text)
    text = re.sub(r'(\d+)\s*(?:y|yo|year|years|old|ë…„ì‚°|ë…„)', r'\1', text)
    text = re.sub(r'[^a-z0-9\s\uac00-\ud7a3]', ' ', text)
    text = re.sub(r'\bì‚°\b', ' ', text)
    return ' '.join(text.split())

def name_clusters(df, cluster_col='cluster'):
    """K-Means í´ëŸ¬ìŠ¤í„°ì— ë™ì ìœ¼ë¡œ ì´ë¦„ì„ ë¶€ì—¬í•©ë‹ˆë‹¤."""
    centroids = df.groupby(cluster_col).agg(
        Total_Volume=('total_volume', 'mean'),
        Avg_UnitPrice=('avg_unitprice', 'mean'),
        Trade_Count=('trade_count', 'mean')
    ).reset_index()
    centroids['volume_rank'] = centroids['Total_Volume'].rank(ascending=False)
    centroids['price_rank'] = centroids['Avg_UnitPrice'].rank(ascending=True)
    centroids['count_rank'] = centroids['Trade_Count'].rank(ascending=False)
    centroids['total_score'] = centroids['volume_rank'] * 0.4 + centroids['price_rank'] * 0.4 + centroids['count_rank'] * 0.2
    sorted_centroids = centroids.sort_values('total_score')
    names = ["ì†Œê·œëª¨/ê³ ê°€ì¹˜ ê·¸ë£¹", "ì¤‘ê²¬/ê· í˜• ê·¸ë£¹", "ëŒ€ê·œëª¨/ê°€ì„±ë¹„ ê·¸ë£¹"]
    name_map = {row[cluster_col]: names[i] if i < len(names) else f"{chr(ord('A')+i)} ê·¸ë£¹" for i, row in sorted_centroids.iterrows()}
    return name_map

def perform_clustering(importer_stats):
    """K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    features = importer_stats[['total_volume', 'avg_unitprice', 'trade_count']].copy()
    if len(features) < 3: return None, None
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
    importer_stats['cluster'] = kmeans.fit_predict(scaled_features)
    cluster_name_map = name_clusters(importer_stats)
    importer_stats['Cluster_Name'] = importer_stats['cluster'].map(cluster_name_map)
    return importer_stats, cluster_name_map

# --- ë©”ì¸ ë¶„ì„ ë¡œì§ ---
def run_all_analysis(user_inputs, full_company_data, selected_products, target_importer_name):
    """í•µì‹¬ ë¶„ì„ ë¡œì§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    analysis_result = {"positioning": {}, "supply_chain": {}}
    analysis_data = full_company_data[full_company_data['reported_product_name'].isin(selected_products)].copy()
    if analysis_data.empty: return analysis_result

    # 1. ìˆ˜ì…ì‚¬ë³„ í†µê³„ ì§‘ê³„
    importer_stats = analysis_data.groupby('importer').agg(
        total_value=('value', 'sum'),
        total_volume=('volume', 'sum'),
        trade_count=('value', 'count'),
        avg_unitprice=('unitprice', 'mean')
    ).reset_index()
    if importer_stats.empty: return analysis_result
    importer_stats = importer_stats.sort_values('total_value', ascending=False).reset_index(drop=True)

    # 2. í¬ì§€ì…”ë‹ ë¶„ì„ (ê·œì¹™ ê¸°ë°˜ + AI ê¸°ë°˜)
    importer_stats['cum_share'] = importer_stats['total_value'].cumsum() / importer_stats['total_value'].sum()
    market_leaders = importer_stats[importer_stats['cum_share'] <= 0.7]
    try:
        target_rank = importer_stats[importer_stats['importer'] == target_importer_name].index[0]
        rank_margin = max(1, int(len(importer_stats) * 0.1))
        direct_peers = importer_stats.iloc[max(0, target_rank - rank_margin):min(len(importer_stats), target_rank + rank_margin + 1)]
    except IndexError: direct_peers = pd.DataFrame()
    price_achievers_candidates = importer_stats[importer_stats['trade_count'] >= 2]
    price_achievers = price_achievers_candidates[price_achievers_candidates['avg_unitprice'] <= price_achievers_candidates['avg_unitprice'].quantile(0.15)] if not price_achievers_candidates.empty else pd.DataFrame()
    clustered_stats, cluster_names = perform_clustering(importer_stats.copy())
    analysis_result['positioning'] = {
        "importer_stats": importer_stats, "clustered_stats": clustered_stats, "cluster_names": cluster_names,
        "rule_based_groups": {"Market Leaders": market_leaders, "Direct Peers": direct_peers, "Price Achievers": price_achievers},
        "target_stats": importer_stats[importer_stats['importer'] == target_importer_name]
    }

    # 3. ê³µê¸‰ë§ ë¶„ì„
    user_input = user_inputs[0]
    user_avg_price = user_input['Value'] / user_input['Volume'] if user_input['Volume'] > 0 else 0
    alternative_suppliers = analysis_data[(analysis_data['exporter'].str.upper() != user_input['Exporter'].upper()) & (analysis_data['unitprice'] < user_avg_price)]
    if not alternative_suppliers.empty:
        supplier_analysis = alternative_suppliers.groupby('exporter').agg(
            avg_unitprice=('unitprice', 'mean'), trade_count=('value', 'count'), num_importers=('importer', 'nunique')
        ).reset_index().sort_values('avg_unitprice')
        supplier_analysis['price_saving_pct'] = (1 - supplier_analysis['avg_unitprice'] / user_avg_price) * 100
        supplier_analysis['stability_score'] = np.log1p(supplier_analysis['trade_count']) + np.log1p(supplier_analysis['num_importers'])
        analysis_result['supply_chain'] = {
            "user_avg_price": user_avg_price, "user_total_volume": sum(item['Volume'] for item in user_inputs), "alternatives": supplier_analysis
        }
    return analysis_result


# --- UI ì»´í¬ë„ŒíŠ¸ ---
def login_screen():
    """ë¡œê·¸ì¸ í™”ë©´ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.title("ğŸ” ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.write("ì†”ë£¨ì…˜ ì ‘ì†ì„ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    with st.form("login_form"):
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.form_submit_button("ì ‘ì†í•˜ê¸°"):
            if password == st.secrets.get("app_secrets", {}).get("password", "tridgeDemo_2025"):
                st.session_state['logged_in'] = True; st.rerun()
            else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def main_dashboard(company_data):
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ UIë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
    st.title("ğŸ“ˆ ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.markdown("íŠ¸ë¦¿ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì¥ ë‚´ ê²½ìŸë ¥ì„ ì§„ë‹¨í•˜ê³  ë¹„ìš© ì ˆê° ê¸°íšŒë¥¼ í¬ì°©í•˜ì„¸ìš”.")

    with st.expander("STEP 1: ë¶„ì„ ì •ë³´ ì…ë ¥", expanded='analysis_groups' not in st.session_state):
        importer_name = st.text_input("1. ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="importer_name_input").upper()
        if 'rows' not in st.session_state: st.session_state['rows'] = [{'id': 1}]

        # --- ìˆ˜í‰ ì…ë ¥ UI ---
        header_cols = st.columns([1.5, 3, 1, 2, 2, 1, 1, 1, 0.5])
        headers = ["ìˆ˜ì…ì¼", "ì œí’ˆ ìƒì„¸ëª…", "HS-CODE", "ì›ì‚°ì§€", "ìˆ˜ì¶œì—…ì²´", "ìˆ˜ì… ì¤‘ëŸ‰(KG)", "ì´ ìˆ˜ì…ê¸ˆì•¡(USD)", "Incoterms", "ì‚­ì œ"]
        for col, header in zip(header_cols, headers): col.markdown(f"**{header}**")

        all_input_data = []
        for i, row in enumerate(st.session_state.rows):
            key_suffix = f"_{row['id']}"
            cols = st.columns([1.5, 3, 1, 2, 2, 1, 1, 1, 0.5])
            
            date_val = cols[0].date_input(f"date{key_suffix}", key=f"date{key_suffix}", label_visibility="collapsed", value=datetime.now())
            product_name_val = cols[1].text_input(f"product_name{key_suffix}", key=f"product_name{key_suffix}", label_visibility="collapsed")
            hscode_val = cols[2].text_input(f"hscode{key_suffix}", max_chars=10, key=f"hscode{key_suffix}", label_visibility="collapsed")
            
            origin_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['export_country'].unique())
            origin_val = cols[3].selectbox(f"origin{key_suffix}", origin_options, key=f"origin{key_suffix}", label_visibility="collapsed", format_func=lambda x: 'ì„ íƒ' if x == '' else x)
            if origin_val == 'ì§ì ‘ ì…ë ¥': origin_val = cols[3].text_input(f"custom_origin{key_suffix}", label_visibility="collapsed", placeholder="ì›ì‚°ì§€ ì§ì ‘ ì…ë ¥")

            exporter_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['exporter'].unique())
            exporter_val = cols[4].selectbox(f"exporter{key_suffix}", exporter_options, key=f"exporter{key_suffix}", label_visibility="collapsed", format_func=lambda x: 'ì„ íƒ' if x == '' else x)
            if exporter_val == 'ì§ì ‘ ì…ë ¥': exporter_val = cols[4].text_input(f"custom_exporter{key_suffix}", label_visibility="collapsed", placeholder="ìˆ˜ì¶œì—…ì²´ ì§ì ‘ ì…ë ¥")

            volume_val = cols[5].number_input(f"volume{key_suffix}", min_value=0.01, format="%.2f", key=f"volume{key_suffix}", label_visibility="collapsed")
            value_val = cols[6].number_input(f"value{key_suffix}", min_value=0.01, format="%.2f", key=f"value{key_suffix}", label_visibility="collapsed")
            incoterms_val = cols[7].selectbox(f"incoterms{key_suffix}", ["FOB", "CFR", "CIF", "EXW", "DDP", "ê¸°íƒ€"], key=f"incoterms{key_suffix}", label_visibility="collapsed")

            if len(st.session_state.rows) > 1 and cols[8].button("ì‚­ì œ", key=f"delete{key_suffix}"):
                st.session_state.rows.pop(i); st.rerun()

            all_input_data.append({
                "Date": date_val, "Reported Product Name": product_name_val, "HS-Code": hscode_val,
                "Origin Country": origin_val, "Exporter": exporter_val, "Volume": volume_val,
                "Value": value_val, "Incoterms": incoterms_val
            })
            
        if st.button("â• ë‚´ì—­ ì¶”ê°€í•˜ê¸°"):
            new_id = max(row['id'] for row in st.session_state.rows) + 1 if st.session_state.rows else 1
            st.session_state.rows.append({'id': new_id}); st.rerun()
        
        st.markdown("---")
        consent = st.checkbox("ì…ë ¥í•˜ì‹  ì •ë³´ëŠ” ë°ì´í„° ë¶„ì„ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ì €ì¥ ë° í™œìš©ë˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤.", value=True)
        
        if st.button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True):
            is_valid = True
            for i, entry in enumerate(all_input_data):
                if not all([entry['Reported Product Name'], entry['HS-Code'], entry['Origin Country'], entry['Exporter'], entry['Volume'] > 0, entry['Value'] > 0]):
                    st.error(f"{i+1}ë²ˆì§¸ ì…ë ¥ ì¤„ì˜ ëª¨ë“  ê°’ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”."); is_valid = False
            if not importer_name: st.error("ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."); is_valid = False
            if not consent: st.warning("ì •ë³´ í™œìš© ë™ì˜ì— ì²´í¬í•´ì£¼ì„¸ìš”."); is_valid = False
            
            if is_valid:
                with st.spinner('ì…ë ¥ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...'):
                    # Google Sheets ì €ì¥
                    for entry in all_input_data:
                        row_to_save = [
                            entry["Date"].strftime('%Y-%m-%d'), entry["Reported Product Name"], entry["HS-Code"],
                            entry["Origin Country"], entry["Exporter"].upper(), entry["Volume"], entry["Value"],
                            entry["Incoterms"], importer_name, consent,
                            datetime.now(ZoneInfo("Asia/Seoul")).strftime('%Y-%m-%d %H:%M:%S')
                        ]
                        save_to_google_sheets(row_to_save)
                    
                    # ë¶„ì„ ë¡œì§ ì‹¤í–‰
                    purchase_df = pd.DataFrame(all_input_data)
                    purchase_df['cleaned_name'] = purchase_df['Reported Product Name'].apply(clean_text)
                    agg_funcs = {'Volume': 'sum', 'Value': 'sum', 'Reported Product Name': 'first', 'HS-Code': 'first', 'Exporter': 'first', 'Date':'first', 'Origin Country':'first', 'Incoterms':'first'}
                    aggregated_purchase_df = purchase_df.groupby('cleaned_name', as_index=False).agg(agg_funcs)

                    analysis_groups = []
                    company_data['cleaned_name'] = company_data['reported_product_name'].apply(clean_text)
                    for _, row in aggregated_purchase_df.iterrows():
                        entry = row.to_dict()
                        user_tokens = set(entry['cleaned_name'].split())
                        is_match = lambda name: user_tokens.issubset(set(str(name).split()))
                        matched_df = company_data[company_data['cleaned_name'].apply(is_match)]
                        matched_products = sorted(matched_df['reported_product_name'].unique().tolist())
                        result = run_all_analysis([entry], company_data, matched_products, importer_name)
                        analysis_groups.append({
                            "user_input": entry, "matched_products": matched_products,
                            "selected_products": matched_products, "result": result
                        })
                    st.session_state['importer_name_result'] = importer_name
                    st.session_state['analysis_groups'] = analysis_groups
                    st.success("ë¶„ì„ ì™„ë£Œ!")
                    st.rerun()
    
    # --- ë¶„ì„ ê²°ê³¼ í‘œì‹œ ---
    if 'analysis_groups' in st.session_state:
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        for i, group in enumerate(st.session_state.analysis_groups):
            product_name = group['user_input']['Reported Product Name']
            st.subheader(f"ë¶„ì„ ê·¸ë£¹: \"{product_name}\"")
            
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì¶”ì¶œ
            result = group['result']
            p_res = result.get('positioning')
            s_res = result.get('supply_chain')
            
            st.markdown("#### PART 1. ë§ˆì¼“ í¬ì§€ì…˜ ë¶„ì„")
            if not p_res or p_res['importer_stats'].empty:
                st.info("í¬ì§€ì…˜ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                continue
    
            # --- ì „ë¬¸ê°€ ì œì•ˆ: ì‚¬ë¶„ë©´ + ê°•ì¡° ë²„ë¸” ì°¨íŠ¸ ---
            importer_stats = p_res['importer_stats']
            target_name = st.session_state.get('importer_name_result', '')
            
            # ì‹œê°í™”í•  ë°ì´í„° ì¤€ë¹„ (Top 5 + ìœ ì‚¬ê·¸ë£¹ + ê·€ì‚¬)
            plot_df = pd.concat([
                importer_stats.head(5), 
                p_res['rule_based_groups']['Direct Peers'], 
                p_res['target_stats']
            ]).drop_duplicates().reset_index(drop=True)
            
            # ìµëª…í™” ë° ì‚¬ì´ì¦ˆ/ìƒ‰ìƒ ì„¤ì •
            plot_df['Anonymized_Importer'] = [f"{chr(ord('A')+j)}ì‚¬" if imp != target_name else target_name for j, imp in enumerate(plot_df['importer'])]
            plot_df['size'] = np.log1p(plot_df['total_value']) # ë¡œê·¸ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë²„ë¸” í¬ê¸° ì¡°ì ˆ
            
            # ê·€ì‚¬ ê°•ì¡°ë¥¼ ìœ„í•œ ìƒ‰ìƒ ë° íˆ¬ëª…ë„ ì„¤ì •
            colors = ['#FF4B4B' if imp == target_name else '#BDBDBD' for imp in plot_df['importer']]
            opacities = [1.0 if imp == target_name else 0.5 for imp in plot_df['importer']]
            plot_df['color'] = colors
            plot_df['opacity'] = opacities
            
            # ì‚¬ë¶„ë©´ ê¸°ì¤€ì„  (ì‹œì¥ í‰ê· ) ê³„ì‚°
            x_mean = importer_stats['total_volume'].mean()
            y_mean = importer_stats['avg_unitprice'].mean()
    
            # ì°¨íŠ¸ ìƒì„±
            fig = px.scatter(
                plot_df, x='total_volume', y='avg_unitprice', size='size',
                color='color', # ê°œë³„ ìƒ‰ìƒ ì ìš©
                opacity=0.8, # ê¸°ë³¸ íˆ¬ëª…ë„
                hover_name='Anonymized_Importer',
                hover_data={'total_volume': ':,', 'avg_unitprice': ':.2f', 'total_value':':,', 'size':False, 'color':False, 'opacity':False},
                log_x=True, title="ìˆ˜ì…ì‚¬ í¬ì§€ì…”ë‹ ë§µ (ì‹œì¥ ì „ëµ ë¶„ì„)"
            )
            
            # ê°œë³„ ì ì— ëŒ€í•œ íˆ¬ëª…ë„ ì§ì ‘ ì„¤ì • (px.scatterì—ì„œ ì§ì ‘ ì§€ì› ì•ˆí•˜ë¯€ë¡œ ìƒì„± í›„ ë³€ê²½)
            for i, o in enumerate(plot_df['opacity']):
                 fig.data[0].marker.color[i] = fig.data[0].marker.color[i].replace('1)', f'{o})').replace('rgb', 'rgba')
    
    
            # í‰ê· ì„  ì¶”ê°€
            fig.add_vline(x=x_mean, line_dash="dash", line_color="gray", annotation_text="í‰ê·  ìˆ˜ì…ëŸ‰")
            fig.add_hline(y=y_mean, line_dash="dash", line_color="gray", annotation_text="í‰ê·  ë‹¨ê°€")
            
            # ì‚¬ë¶„ë©´ í…ìŠ¤íŠ¸ ì¶”ê°€
            chart_max_x = plot_df['total_volume'].max() * 1.5 # ë¡œê·¸ ìŠ¤ì¼€ì¼ ê°ì•ˆ
            chart_max_y = plot_df['avg_unitprice'].max() * 1.1
            
            fig.add_annotation(x=np.log10(chart_max_x), y=chart_max_y, text="<b>ë‹ˆì¹˜/í”„ë¦¬ë¯¸ì—„ ê·¸ë£¹</b>", showarrow=False, xanchor='right', yanchor='top', font=dict(color="grey", size=12))
            fig.add_annotation(x=np.log10(x_mean*0.95), y=chart_max_y, text="<b>ì‹œì¥ ì„ ë„ ê·¸ë£¹</b>", showarrow=False, xanchor='right', yanchor='top', font=dict(color="grey", size=12))
            fig.add_annotation(x=np.log10(chart_max_x), y=plot_df['avg_unitprice'].min(), text="<b>ì†Œê·œëª¨/ê°€ê²© ê²½ìŸ ê·¸ë£¹</b>", showarrow=False, xanchor='right', yanchor='bottom', font=dict(color="grey", size=12))
            fig.add_annotation(x=np.log10(x_mean*0.95), y=plot_df['avg_unitprice'].min(), text="<b>ëŒ€ê·œëª¨/ê°€ì„±ë¹„ ê·¸ë£¹</b>", showarrow=False, xanchor='right', yanchor='bottom', font=dict(color="grey", size=12))
    
            # ê·€ì‚¬ ìœ„ì¹˜ì— í™”ì‚´í‘œ ì¶”ê°€
            target_row = plot_df[plot_df['importer'] == target_name]
            if not target_row.empty:
                target = target_row.iloc[0]
                fig.add_annotation(
                    x=np.log10(target['total_volume']), y=target['avg_unitprice'],
                    text="<b>ê·€ì‚¬ ìœ„ì¹˜</b>", showarrow=True, arrowhead=2, arrowcolor="#FF4B4B",
                    ax=-40, ay=-40, bordercolor="#FF4B4B", borderwidth=2, bgcolor="white"
                )
    
            fig.update_layout(
                xaxis_title="ì´ ìˆ˜ì… ì¤‘ëŸ‰ (KG, Log Scale)", yaxis_title="í‰ê·  ìˆ˜ì… ë‹¨ê°€ (USD/KG)",
                showlegend=False # ë²”ë¡€ ìˆ¨ê¸°ê¸°
            )
        st.plotly_chart(fig, use_container_width=True)
            # ê·¸ë£¹ ë¶„ë¥˜ ë°©ì‹ ì„ íƒ
            st.markdown("##### ê²½ìŸì‚¬ ê·¸ë£¹ ë¶„ì„")
            grouping_method = st.radio("ê·¸ë£¹ ë¶„ë¥˜ ë°©ì‹ ì„ íƒ:", ["ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹", "AI ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘ (K-Means)"], horizontal=True, key=f"group_method_{i}")
            if grouping_method == "ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹": st.info("ì‹œì¥ ì„ ë„(ëˆ„ì  ì ìœ ìœ¨ 70%), ìœ ì‚¬ ê·œëª¨(ìˆœìœ„ Â±10%), ìµœì €ê°€ ë‹¬ì„±(ë‹¨ê°€ í•˜ìœ„ 15%) ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
            else:
                if p_res.get('clustered_stats') is not None:
                    st.info("AIê°€ ìˆ˜ì… ê·œëª¨, ë‹¨ê°€, ë¹ˆë„ë¥¼ ì¢…í•©í•˜ì—¬ ìœ ì‚¬í•œ ì—…ì²´ë¼ë¦¬ 3ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
                    fig_box = px.box(p_res['clustered_stats'], x='Cluster_Name', y='avg_unitprice', title="AI ê¸°ë°˜ ê·¸ë£¹ë³„ ë‹¨ê°€ ë¶„í¬", points='all', labels={'Cluster_Name': 'ê·¸ë£¹ ìœ í˜•', 'avg_unitprice': 'í‰ê·  ìˆ˜ì… ë‹¨ê°€'})
                    if not p_res['target_stats'].empty:
                        fig_box.add_hline(y=p_res['target_stats']['avg_unitprice'].iloc[0], line_dash="dot", line_color="orange", annotation_text="ê·€ì‚¬ ë‹¨ê°€")
                    st.plotly_chart(fig_box, use_container_width=True)
                else: st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ AI ê¸°ë°˜ ê·¸ë£¹í•‘ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê³µê¸‰ë§ ë¶„ì„
            st.markdown("---")
            st.markdown("#### PART 2. ê³µê¸‰ë§ ë¶„ì„ ë° ë¹„ìš© ì ˆê° ì‹œë®¬ë ˆì´ì…˜")
            if not s_res or s_res['alternatives'].empty: st.info("í˜„ì¬ ê±°ë˜ ì¡°ê±´ë³´ë‹¤ ë” ì €ë ´í•œ ëŒ€ì•ˆ ê³µê¸‰ì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                alts, best_deal = s_res['alternatives'], s_res['alternatives'].iloc[0]
                st.success(f"**ë¹„ìš© ì ˆê° ê¸°íšŒ í¬ì°©!** í˜„ì¬ ê±°ë˜ì²˜ë³´ë‹¤ **ìµœëŒ€ {best_deal['price_saving_pct']:.1f}%** ì €ë ´í•œ ëŒ€ì²´ ê±°ë˜ì²˜ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
                col1, col2 = st.columns(2)
                target_saving_pct = col1.slider("ëª©í‘œ ë‹¨ê°€ ì ˆê°ë¥ (%)", 0.0, float(best_deal['price_saving_pct']), float(best_deal['price_saving_pct'] / 2), 0.5, "%.1f%%")
                expected_saving = s_res['user_total_volume'] * s_res['user_avg_price'] * (target_saving_pct / 100)
                col2.metric(f"ì˜ˆìƒ ì ˆê°ì•¡ (ìˆ˜ì…ëŸ‰ {s_res['user_total_volume']:,.0f}KG ê¸°ì¤€)", f"${expected_saving:,.0f}")
                
                st.markdown("##### **ì¶”ì²œ ëŒ€ì²´ ê³µê¸‰ì²˜ ë¦¬ìŠ¤íŠ¸** (ì•ˆì •ì„± í•¨ê»˜ ê³ ë ¤)")
                recommended_list = alts[alts['price_saving_pct'] >= target_saving_pct].copy()
                recommended_list.rename(columns={'exporter': 'ìˆ˜ì¶œì—…ì²´', 'avg_unitprice': 'í‰ê·  ë‹¨ê°€', 'price_saving_pct': 'ê°€ê²© ê²½ìŸë ¥(%)', 'trade_count': 'ê±°ë˜ ë¹ˆë„', 'num_importers': 'ê±°ë˜ì²˜ ìˆ˜', 'stability_score': 'ê³µê¸‰ ì•ˆì •ì„±'}, inplace=True)
                st.dataframe(
                    recommended_list[['ìˆ˜ì¶œì—…ì²´', 'í‰ê·  ë‹¨ê°€', 'ê°€ê²© ê²½ìŸë ¥(%)', 'ê±°ë˜ ë¹ˆë„', 'ê±°ë˜ì²˜ ìˆ˜', 'ê³µê¸‰ ì•ˆì •ì„±']], use_container_width=True,
                    column_config={
                        "í‰ê·  ë‹¨ê°€": st.column_config.NumberColumn(format="$%.2f"),
                        "ê°€ê²© ê²½ìŸë ¥(%)": st.column_config.ProgressColumn(format="%.1f%%", min_value=0, max_value=alts['price_saving_pct'].max()),
                        "ê³µê¸‰ ì•ˆì •ì„±": st.column_config.BarChartColumn(y_min=0, y_max=alts['stability_score'].max())
                    }, hide_index=True
                )
            st.markdown("---")

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False

if not st.session_state['logged_in']:
    login_screen()
else:
    company_data = load_company_data()
    if company_data is not None:
        main_dashboard(company_data)
    else:
        st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
