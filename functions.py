import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import re
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials
from pandas_gbq import read_gbq
import calendar
from zoneinfo import ZoneInfo

# --- ì´ˆê¸° ì„¤ì • ë° í˜ì´ì§€ êµ¬ì„± ---
st.set_page_config(layout="wide", page_title="ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")

# --- ë°ì´í„° ë¡œë”© (BigQuery ë°©ì‹ì— ë§ì¶¤) ---
@st.cache_data(ttl=3600)
def load_company_data():
    """Google BigQueryì—ì„œ TDSë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    try:
        if "gcp_service_account" not in st.secrets:
            st.error("Secrets ì„¤ì • ì˜¤ë¥˜: [gcp_service_account] ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"])
        project_id = st.secrets["gcp_service_account"]["project_id"]
        dataset_id = "demo_data" 
        table_id = "tds_data"   
        table_full_id = f"{project_id}.{dataset_id}.{table_id}"
        dataset_location = "asia-northeast3" 
        query = f"SELECT * FROM `{table_full_id}`"
        df = read_gbq(query, project_id=project_id, credentials=creds, location=dataset_location)
        
        if df.empty:
            st.error("BigQuery í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ì§€ë§Œ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        df.columns = [re.sub(r'[^a-z0-9]+', '_', col.lower().strip()) for col in df.columns]

        required_cols = ['date', 'volume', 'value', 'reported_product_name', 'export_country', 'exporter', 'importer', 'hs_code']
        for col in required_cols:
            if col not in df.columns:
                st.error(f"BigQuery í…Œì´ë¸” ì˜¤ë¥˜: í•„ìˆ˜ ì»¬ëŸ¼ '{col}'ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.info(f"BigQuery í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… (ìˆ˜ì • í›„): {df.columns.tolist()}")
                return None
        
        def smart_numeric_conversion(series):
            if pd.api.types.is_numeric_dtype(series): return pd.to_numeric(series, errors='coerce')
            series_str = series.astype(str)
            series_cleaned = series_str.str.replace(r'[^\d.]', '', regex=True)
            return pd.to_numeric(series_cleaned, errors='coerce')

        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['volume'] = smart_numeric_conversion(df['volume'])
        df['value'] = smart_numeric_conversion(df['value'])
        df.dropna(subset=['date', 'volume', 'value'], inplace=True)
        
        if df.empty:
            st.error("ë°ì´í„° ì •ì œ í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
        st.exception(e)
        return None

# --- ë¶„ì„ í—¬í¼ í•¨ìˆ˜ ---
def create_monthly_frequency_chart(df, title):
    df['date'] = pd.to_datetime(df['date'])
    end_date = datetime.now()
    start_date = end_date - pd.DateOffset(years=1)
    df_filtered = df[(df['date'] >= start_date) & (df['date'] <= end_date)].copy()
    if df_filtered.empty: return None
    df_filtered['Month'] = df_filtered['date'].dt.to_period('M').astype(str)
    monthly_counts = df_filtered.groupby('Month').size().reset_index(name='counts')
    all_months = pd.date_range(start=start_date, end=end_date, freq='MS').to_period('M').astype(str)
    all_months_df = pd.DataFrame({'Month': all_months})
    monthly_counts = pd.merge(all_months_df, monthly_counts, on='Month', how='left').fillna(0)
    fig = px.bar(monthly_counts, x='Month', y='counts', title=title, labels={'Month': 'ì›”', 'counts': 'ìˆ˜ì… ê±´ìˆ˜'})
    fig.update_layout(margin=dict(t=40, b=20, l=40, r=20), height=300, plot_bgcolor='white')
    return fig

# --- ìƒˆë¡œìš´ ë²”ìš© ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ ë¡œì§ ---
def clean_text(text):
    if not isinstance(text, str): return ''
    text = text.lower()
    text = re.sub(r'\(.*?\)|\[.*?\]', ' ', text)
    text = re.sub(r'(\d+)\s*(?:y|yo|year|years|old|ë…„)', r'\1', text)
    text = re.sub(r'[^a-z0-9\s\uac00-\ud7a3]', ' ', text)
    return ' '.join(text.split())

# --- ë©”ì¸ ë¶„ì„ ë¡œì§ ---
def run_all_analysis(user_input, company_data, target_importer_name):
    analysis_result = {"overview": None, "positioning": None, "supply_chain": None}
    
    company_data['unitPrice'] = company_data['value'] / company_data['volume']
    
    # 0. Overview ë¶„ì„
    hscode_data = company_data[company_data['hs_code'] == user_input['HS-CODE']]
    if not hscode_data.empty:
        this_year = datetime.now().year
        last_year = this_year - 1
        
        vol_this_year = hscode_data[hscode_data['date'].dt.year == this_year]['volume'].sum()
        vol_last_year = hscode_data[hscode_data['date'].dt.year == last_year]['volume'].sum()
        price_this_year = hscode_data[hscode_data['date'].dt.year == this_year]['unitPrice'].mean()
        price_last_year = hscode_data[hscode_data['date'].dt.year == last_year]['unitPrice'].mean()

        analysis_result['overview'] = {
            "vol_this_year": vol_this_year, "vol_last_year": vol_last_year,
            "price_this_year": price_this_year, "price_last_year": price_last_year,
            "freq_this_year": len(hscode_data[hscode_data['date'].dt.year == this_year]),
            "product_composition": hscode_data.groupby('reported_product_name')['value'].sum().reset_index()
        }

    # 1. í¬ì§€ì…”ë‹ ë¶„ì„
    importer_stats = company_data.groupby('importer').agg(
        Total_Value=('value', 'sum'), Total_Volume=('volume', 'sum'), Trade_Count=('value', 'count')
    ).reset_index()
    
    if not importer_stats.empty and importer_stats['Total_Volume'].sum() > 0:
        importer_stats['Avg_UnitPrice'] = importer_stats['Total_Value'] / importer_stats['Total_Volume']
        importer_stats = importer_stats.sort_values('Total_Value', ascending=False).reset_index(drop=True)

        total_market_value = importer_stats['Total_Value'].sum()
        importer_stats['cum_share'] = importer_stats['Total_Value'].cumsum() / total_market_value
        market_leaders = importer_stats[importer_stats['cum_share'] <= 0.7]

        try:
            target_rank = importer_stats[importer_stats['importer'] == target_importer_name].index[0]
            rank_margin = int(len(importer_stats) * 0.1)
            peer_min_rank, peer_max_rank = max(0, target_rank - rank_margin), min(len(importer_stats), target_rank + rank_margin + 1)
            direct_peers = importer_stats.iloc[peer_min_rank:peer_max_rank]
        except IndexError: direct_peers = pd.DataFrame()

        price_achievers_candidates = importer_stats[importer_stats['Trade_Count'] >= 1]
        if not price_achievers_candidates.empty:
            price_quantile = price_achievers_candidates['Avg_UnitPrice'].quantile(0.15)
            price_achievers = price_achievers_candidates[price_achievers_candidates['Avg_UnitPrice'] <= price_quantile]
        else: price_achievers = pd.DataFrame()
        
        analysis_result['positioning'] = {
            "bubble_data": importer_stats, "market_leaders": market_leaders,
            "direct_peers": direct_peers, "price_achievers": price_achievers,
            "target_stats": importer_stats[importer_stats['importer'] == target_importer_name]
        }
    
    # 2. ê³µê¸‰ë§ ë¶„ì„
    # ... (ìƒëµ)
    
    return analysis_result

# --- UI Components ---
def login_screen():
    st.title("ğŸ” ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.write("ì†”ë£¨ì…˜ ì ‘ì†ì„ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    with st.form("login_form", clear_on_submit=True):
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        submitted = st.form_submit_button("ì ‘ì†í•˜ê¸°")
        if submitted:
            if password == "tridgeDemo_2025":
                st.session_state['logged_in'] = True
                st.rerun()
            else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def main_dashboard(company_data):
    st.title("ğŸ“ˆ ìˆ˜ì… ê²½ìŸë ¥ ì§„ë‹¨ ì†”ë£¨ì…˜")
    st.markdown("íŠ¸ë¦¿ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì¥ ë‚´ ê²½ìŸë ¥ì„ ì§„ë‹¨í•˜ê³  ë¹„ìš© ì ˆê° ê¸°íšŒë¥¼ í¬ì°©í•˜ì„¸ìš”.")

    with st.expander("STEP 1: ë¶„ì„ ì •ë³´ ì…ë ¥", expanded='analysis_groups' not in st.session_state):
        importer_name = st.text_input("1. ê·€ì‚¬ì˜ ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="importer_name").upper()
        if 'rows' not in st.session_state: st.session_state['rows'] = [{'id': 1}]
        
        for i, row in enumerate(st.session_state.rows):
            cols = st.columns([2, 3, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1])
            cols[0].date_input("ìˆ˜ì…ì¼", key=f"date_{i}")
            cols[1].text_input("ì œí’ˆ ìƒì„¸ëª…", placeholder="ì˜ˆ : ì—‘ìŠ¤íŠ¸ë¼ë²„ì§„ ì˜¬ë¦¬ë¸Œìœ ", key=f"product_name_{i}")
            cols[2].text_input("HS-CODE(6ìë¦¬)", max_chars=6, key=f"hscode_{i}")
            
            origin_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['export_country'].unique())
            selected_origin = cols[3].selectbox("ì›ì‚°ì§€", origin_options, key=f"origin_{i}", format_func=lambda x: 'ì„ íƒ ë˜ëŠ” ì§ì ‘ ì…ë ¥' if x == '' else x)
            if selected_origin == 'ì§ì ‘ ì…ë ¥':
                cols[3].text_input("â”” ì›ì‚°ì§€ ì§ì ‘ ì…ë ¥", key=f"custom_origin_{i}", placeholder="ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”")

            exporter_options = [''] + ['ì§ì ‘ ì…ë ¥'] + sorted(company_data['exporter'].unique())
            selected_exporter = cols[4].selectbox("ìˆ˜ì¶œì—…ì²´", exporter_options, key=f"exporter_{i}", format_func=lambda x: 'ì„ íƒ ë˜ëŠ” ì§ì ‘ ì…ë ¥' if x == '' else x)
            if selected_exporter == 'ì§ì ‘ ì…ë ¥':
                cols[4].text_input("â”” ìˆ˜ì¶œì—…ì²´ ì§ì ‘ ì…ë ¥", key=f"custom_exporter_{i}", placeholder="ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”")

            cols[5].number_input("ìˆ˜ì… ì¤‘ëŸ‰(KG)", min_value=0.01, format="%.2f", key=f"volume_{i}")
            cols[6].number_input("ì´ ìˆ˜ì…ê¸ˆì•¡(USD)", min_value=0.01, format="%.2f", key=f"value_{i}")
            cols[7].selectbox("Incoterms", ["FOB", "CFR", "CIF", "EXW", "DDP", "ê¸°íƒ€"], key=f"incoterms_{i}")
            if len(st.session_state.rows) > 1 and cols[8].button("ì‚­ì œ", key=f"delete_{i}"):
                st.session_state.rows.pop(i)
                st.rerun()

        if st.button("â• ë‚´ì—­ ì¶”ê°€í•˜ê¸°"):
            st.session_state.rows.append({'id': len(st.session_state.rows) + 1})
            st.rerun()
        st.markdown("---")
        consent = st.checkbox("ì…ë ¥í•˜ì‹  ì •ë³´ëŠ” ë°ì´í„° ë¶„ì„ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ì €ì¥ ë° í™œìš©ë˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤.")
        analyze_button = st.button("ë¶„ì„í•˜ê¸°", type="primary")

    if analyze_button:
        if not importer_name: st.warning("ìˆ˜ì…ì—…ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not consent: st.warning("ë°ì´í„° í™œìš© ë™ì˜ì— ì²´í¬í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œíŠ¸ì— ì €ì¥ ì¤‘ì…ë‹ˆë‹¤...'):
                all_purchase_data = []
                for i in range(len(st.session_state.rows)):
                    user_product_name = st.session_state[f'product_name_{i}']
                    origin_val = st.session_state[f'origin_{i}']
                    if origin_val == 'ì§ì ‘ ì…ë ¥': origin_val = st.session_state.get(f'custom_origin_{i}', "")
                    exporter_val = st.session_state[f'exporter_{i}']
                    if exporter_val == 'ì§ì ‘ ì…ë ¥': exporter_val = st.session_state.get(f'custom_exporter_{i}', "")
                    entry = { 'Date': st.session_state[f'date_{i}'], 'Reported Product Name': user_product_name, 'HS-CODE': st.session_state[f'hscode_{i}'], 'Origin Country': origin_val.upper(), 'Exporter': exporter_val.upper(), 'Volume': st.session_state[f'volume_{i}'], 'Value': st.session_state[f'value_{i}'], 'Incoterms': st.session_state[f'incoterms_{i}'] }
                    if not user_product_name or not origin_val or not exporter_val:
                        st.error(f"{i+1}ë²ˆì§¸ í–‰ì˜ 'ì œí’ˆ ìƒì„¸ëª…', 'ì›ì‚°ì§€', 'ìˆ˜ì¶œì—…ì²´'ëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.")
                        return
                    all_purchase_data.append(entry)
                
                # ì¤‘ë³µ ì œí’ˆ í•©ì‚° ë¡œì§
                purchase_df = pd.DataFrame(all_purchase_data)
                agg_funcs = {'Volume': 'sum', 'Value': 'sum', 'Date': 'first', 'HS-CODE': 'first', 'Origin Country': 'first', 'Exporter': 'first', 'Incoterms': 'first'}
                aggregated_purchase_df = purchase_df.groupby('Reported Product Name').agg(agg_funcs).reset_index()

                analysis_groups = []
                company_data['cleaned_name'] = company_data['reported_product_name'].apply(clean_text)
                
                for i, row in aggregated_purchase_df.iterrows():
                    entry = row.to_dict()
                    user_tokens = set(clean_text(entry['Reported Product Name']).split())
                    def is_match(cleaned_tds_name): return user_tokens.issubset(set(cleaned_tds_name.split()))
                    matched_df = company_data[company_data['cleaned_name'].apply(is_match)]
                    analysis_groups.append({ "id": i, "user_input": entry, "matched_products": sorted(matched_df['reported_product_name'].unique().tolist()), "selected_products": sorted(matched_df['reported_product_name'].unique().tolist()) })

                try:
                    # ... (Google Sheets ì €ì¥ ë¡œì§) ...
                    pass
                except Exception as e:
                    st.error(f"Google Sheets ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

                st.session_state['importer_name_result'] = importer_name
                st.session_state['analysis_groups'] = analysis_groups
                st.rerun()

    if 'analysis_groups' in st.session_state:
        st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        
        with st.expander("STEP 2: ë¶„ì„ ëŒ€ìƒ ì œí’ˆ í•„í„°ë§", expanded=True):
            for i, group in enumerate(st.session_state.analysis_groups):
                st.markdown(f"**ë¶„ì„ ê·¸ë£¹: \"{group['user_input']['Reported Product Name']}\"**")
                selected = st.multiselect(
                    "ì´ ê·¸ë£¹ì˜ ë¶„ì„ì— í™œìš©í•  ì œí’ˆëª…ì„ ì„ íƒí•˜ì„¸ìš”.",
                    options=group['matched_products'],
                    default=group['selected_products'],
                    key=f"filter_{group['id']}"
                )
                st.session_state.analysis_groups[i]['selected_products'] = selected
                st.markdown("---")

        for group in st.session_state.analysis_groups:
            st.subheader(f"ë¶„ì„ ê²°ê³¼: \"{group['user_input']['Reported Product Name']}\"")
            
            if not group['selected_products']:
                st.warning("ì„ íƒëœ ë¹„êµ ëŒ€ìƒ ì œí’ˆì´ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            analysis_data = company_data[company_data['reported_product_name'].isin(group['selected_products'])]
            result = run_all_analysis(group['user_input'], analysis_data, st.session_state['importer_name_result'])

            # 0. Overview í‘œì‹œ
            st.markdown("### 0. Overview")
            if result.get('overview'):
                o = result['overview']
                st.markdown(f"#### HS-Code {group['user_input']['HS-CODE']}ì˜ ìˆ˜ì… ì „ë°˜ ìš”ì•½")
                # ... (ê²°ê³¼ í‘œì‹œ)
            else:
                st.info("HS-Codeì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ Overview ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤.")

            # 1. Positioning í‘œì‹œ
            st.markdown(f"### 1. {st.session_state['importer_name_result']}ì„ ìœ„í•œ ìˆ˜ì… ì§„ë‹¨ ë° í¬ì§€ì…”ë‹ ê²°ê³¼")
            if result.get('positioning'):
                p = result['positioning']
                st.markdown("#### PART 1. ë§ˆì¼“ í¬ì§€ì…˜ ë¶„ì„")
                
                all_importers = p['bubble_data']['importer'].unique()
                anonymity_map = {name: f"{chr(65+i)}ì‚¬" for i, name in enumerate(all_importers) if name != st.session_state['importer_name_result']}
                
                bubble_df = p['bubble_data'].copy()
                bubble_df['Anonymized_Importer'] = bubble_df['importer'].apply(lambda x: "ê·€ì‚¬" if x == st.session_state['importer_name_result'] else anonymity_map.get(x, "ê¸°íƒ€"))
                
                fig_bubble = px.scatter(bubble_df, x='Total_Volume', y='Avg_UnitPrice', size='Total_Value', color='Anonymized_Importer',
                                        hover_name='Anonymized_Importer', size_max=60,
                                        labels={'Total_Volume': 'ìˆ˜ì… ì´ ì¤‘ëŸ‰ (KG)', 'Avg_UnitPrice': 'í‰ê·  ìˆ˜ì… ë‹¨ê°€ (USD/KG)'})
                st.plotly_chart(fig_bubble, use_container_width=True)

                st.markdown("##### ì§€ë‚œ 12ê°œì›”ê°„ ì›”ë³„ ìˆ˜ì… ë¹ˆë„")
                target_df = company_data[company_data['importer'] == st.session_state['importer_name_result']]
                fig_target_freq = create_monthly_frequency_chart(target_df, "ê·€ì‚¬")
                if fig_target_freq: st.plotly_chart(fig_target_freq, use_container_width=True)
                else: st.info("ê·€ì‚¬ì˜ ì§€ë‚œ 1ë…„ê°„ ìˆ˜ì… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            else:
                st.info("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í¬ì§€ì…”ë‹ ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤.")

        if st.button("ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
            keys_to_keep = ['logged_in']
            for key in list(st.session_state.keys()):
                if key not in keys_to_keep: del st.session_state[key]
            st.rerun()

# --- ë©”ì¸ ë¡œì§ ---
if 'logged_in' not in st.session_state: 
    st.session_state['logged_in'] = False

if st.session_state['logged_in']:
    our_company_data = load_company_data()
    if our_company_data is not None:
        main_dashboard(our_company_data)
else:
    login_screen()
